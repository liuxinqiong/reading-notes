## 颜色表示
Web 系统中表示颜色的基本方法
* RGB 和 RGBA
* HSL 和 HSV
* CIE Lab 和 CIE Lch
* Cubehelix 色盘

### RGB
RGB 颜色是将人眼可见的颜色表示为红、绿、蓝三原色不同色阶的混合。

RGB 不能表示人眼所能见到的所有颜色，只能表示这其中的一个区域。

> WebGL 的 shader 默认支持 RGBA。因为在 WebGL 的 shader 中，我们是使用一个四维向量来表示颜色的，向量的 r、g、b、a 分量分别表示红色、绿色、蓝色和 alpha 通道。不过和 CSS 的颜色表示稍有不同的是，WebGL 采用归一化的浮点数值，也就是说，WebGL 的颜色分量 r、g、b、a 的数值都是 0 到 1 之间的浮点数。

RGB 颜色表示的局限性：我们只能大致直观地判断出它偏向于红色、绿色还是蓝色，或者在颜色立方体的大致位置。所以，在对比两个 RGB 颜色的时候，我们只能通过对比它们在 RGB 立方体中的相对距离，来判断它们的颜色差异。除此之外，我们几乎就得不到其他任何有用的信息了。**当要选择一组颜色给图表使用时，我们并不知道要以什么样的规则来配置颜色，才能让不同数据对应的图形之间的对比尽可能鲜明**。因此，RGB 颜色对用户其实并不友好。

在需要动态构建视觉颜色效果的时候，我们很少直接选用 RGB 色值，而是使用其他的颜色表示形式。这其中，比较常用的就是 HSL 和 HSV 颜色表示形式。

### HSL 和 HSV
与 RGB 颜色以色阶表示颜色不同，HSL 和 HSV 用色相（Hue）、饱和度（Saturation）和亮度（Lightness）或明度（Value）来表示颜色。其中，Hue 是角度，取值范围是 0 到 360 度，饱和度和亮度 / 明度的值都是从 0 到 100%。

HSL 和 HSV 是怎么表示颜色的呢？实际上，我们可以把 HSL 和 HSV 颜色理解为，是将 RGB 颜色的立方体从直角坐标系投影到极坐标的圆柱上，所以它的色值和 RGB 色值是一一对应的。

RGB 和 hsv 之间色值的互转算法比较复杂。不过好在，CSS 和 Canvas2D 都可以直接支持 HSL 颜色，只有 WebGL 需要做转换。示例代码如下
```glsl
vec3 rgb2hsv(vec3 c){
  vec4 K = vec4(0.0, -1.0 / 3.0, 2.0 / 3.0, -1.0);
  vec4 p = mix(vec4(c.bg, K.wz), vec4(c.gb, K.xy), step(c.b, c.g));
  vec4 q = mix(vec4(p.xyw, c.r), vec4(c.r, p.yzx), step(p.x, c.r));
  float d = q.x - min(q.w, q.y);
  float e = 1.0e-10;
  return vec3(abs(q.z + (q.w - q.y) / (6.0 * d + e)), d / (q.x + e), q.x);
}

vec3 hsv2rgb(vec3 c){
  vec3 rgb = clamp(abs(mod(c.x*6.0+vec3(0.0,4.0,2.0), 6.0)-3.0)-1.0, 0.0, 1.0);
  rgb = rgb * rgb * (3.0 - 2.0 * rgb);
  return c.z * mix(vec3(1.0), rgb, c.y);
}
```
HSL 依然不是最完美的颜色方法，我们还需要建立一套针对人类知觉的标准，这个标准在描述颜色的时候要尽可能地满足以下 2 个原则：
* 人眼看到的色差 = 颜色向量间的欧氏距离
* 相同的亮度，能让人感觉亮度相同

一个针对人类感觉的颜色描述方式就产生了，它就是 CIE Lab。

### CIE Lab 和 CIE Lch 颜色
CIE Lab 颜色空间简称 Lab，它其实就是一种符合人类感觉的色彩空间，它用 L 表示亮度，a 和 b 表示颜色对立度。RGB 值也可以 Lab 转换，但是转换规则比较复杂。

CIE Lab 比较特殊的一点是，目前还没有能支持 CIE Lab 的图形系统，但是 css-color level4规范已经给出了 Lab 颜色值的定义。一些 JavaScript 库也已经可以直接处理 Lab 颜色空间了，如 d3-color。

在以 CIELab 方式呈现的色彩变化中，我们设置的数值和人眼感知的一致性比较强。而 CIE Lch 和 CIE Lab 的对应方式类似于 RGB 和 HSL 和 HSV 的对应方式，也是将坐标从立方体的直角坐标系变换为圆柱体的极坐标系。

### Cubehelix 色盘
一种特殊的颜色表示法，Cubehelix 色盘（立方螺旋色盘）。简单来说，它的原理就是在 RGB 的立方中构建一段螺旋线，让色相随着亮度增加螺旋变换。

具体可以通过 cubehelix npm 包把玩一下。

### 总结
在可视化应用里，一般有两种使用颜色的方式：
* 第一种，整个项目的 UI 配色全部由 UI 设计师设计好，提供给可视化工程师使用。那在这种情况下，设计师设计的颜色是多少就是多少，开发者使用任何格式的颜色都行。
* 第二种方式就是根据数据情况由前端动态地生成颜色值。当然不会是整个项目都由开发者完全自由选择，而一般是由设计师定下视觉基调和一些主色，开发者根据主色和数据来生成对应的颜色。

RGB 用三原色的色阶来表示颜色，是最基础的颜色表示法，但是它对用户不够友好。而 HSL 和 HSV 是用色相、饱和度、亮度（明度）来表示颜色，对开发者比较友好，但是它的数值变换与人眼感知并不完全相符。

CIELab 和 CIELch 与 Cubehelix 色盘，这两种颜色表示法还比较新，在实际工作中使用得不是很多。其中，CIELab 和 CIELch 是与人眼感知相符的色彩空间表示法，已经被纳入 css-color level4 规范中。虽然还没有被浏览器支持，但是一些如 d3-color 这样的 JavaScript 库可以直接处理 Lab 颜色空间。而如果我们要呈现颜色随数据动态改变的效果，那 Cubehelix 色盘就是一种非常更合适的选择了。

在可视化中，我们会使用图形的大小、高低、宽窄、颜色和形状这些常见信息来反映数据。一般来说，我们会使用一种叫做二维强化的技巧，来叠加两个维度的信息，从而加强可视化的视觉呈现效果。

## 图案生成
图案就是用来修饰这些几何图形，强化视觉效果的，所以图案一般是指几何图形上的花纹。这些花纹有的简单，有的复杂，有的规律明显，有的看上去比较随机。也正是因为图案可以如此的不同，它们才能更好地增强视觉效果。

三种最常用的图案生成方法论，分别是重复图案、分形图案和随机图案。

如何绘制大批量重复图案
* 使用 background-image 来绘制重复图案，巧妙利用 background-repeat 机制
* 使用 shader 绘制重复图案，充分发挥 GPU 并行计算的特点

关于基础库 gl-renderer 的使用，gl-renderer 在 WebGL 底层的基础上进行了一些简单的封装，以便于我们将重点放在提供几何数据、设置变量和编写 Shader 上，不用因为创建 buffer 等细节而分心。如何绘制一个网格 demo
```js
//第一步:
const canvas = document.querySelector('canvas');
const renderer = new GlRenderer(canvas);

//第二步:
const program = renderer.compileSync(fragment, vertex);
renderer.useProgram(program);

//表示每一行显示多少个网格
renderer.uniforms.rows = 64;

//步骤四是将顶点数据送入缓冲区。
renderer.setMeshData([{
  positions: [
    [-1, -1],
    [-1, 1],
    [1, 1],
    [1, -1],
  ],
  attributes: {
    // 纹理坐标，左下角 0，0，右上角 1，1
    uv: [
      [0, 0],
      [0, 1],
      [1, 1],
      [1, 0],
    ],
  },
  // 顶点索引
  cells: [[0, 1, 2], [2, 0, 3]],
}]);

// 进行渲染
renderer.render()

// fragment
void main() {
  // fract 用来获取一个数的小数部分
  vec2 st = fract(vUv * rows);
  // 阶梯函数：当 step(a, b) 中的 b < a 时，返回 0；当 b >= a 时，返回 1。因为 WebGL 中的片元着色器线性插值，所以现在它们默认是线性变化的，而我们要的是阶梯变化。
  float d1 = step(st.x, 0.9);
  float d2 = step(0.1, st.y);
  // mix 是线性插值函数，mix(a, b, c) 表示根据 c 是 0 或 1，返回 a 或者 b。
  gl_FragColor.rgb = mix(vec3(0.8), vec3(1.0), d1 * d2);
  // alpha 通道
  gl_FragColor.a = 1.0;
}
```

上述实现网格的优势在于，不管我们给 rows 取值多少，图案都是一次绘制出来的，并不会因为 rows 增加而消耗性能。所以，使用 Shader 绘制重复图案，不管绘制多么细腻，图案重复多少次，绘制消耗的时间几乎是常量，不会遇到性能瓶颈。

如何绘制分形图案
* 一个分形图案可以划分成无数个部分，而每个部分的形状又都和这个图案整体具有相似性。所以，典型的分形效果具有局部与整体的自相似性以及无限细节（分形可以无限放大），能产生令人震撼的视觉效果。
* 分形公式，Mandelbrot Set，也叫曼德勃罗特集。这个公式中 Zn Zn+1是复数，C 是一个实数常量。Zn+1 = Zn^2 + C

如何给图案增加随机效果：在片元着色器中使用伪随机函数，来给重复图案实现随机效果。

## 滤镜函数
在可视化领域里，我们常常需要处理大规模的数据，比如，需要呈现数万甚至数十万条信息在空间中的分布情况。如果我们用几何绘制的方式将这些信息一一绘制出来，性能可能就会很差。

这时，我们就可以将这些数据简化为像素点进行处理。这种处理图像的新思路就叫做像素化。在可视化应用中，图片像素化处理是一个很重要手段，它能够在我们将原始数据信息转换成图形后，进一步处理图形的细节，突出我们想要表达的信息，还能让视觉呈现更有冲击力。

了解图片像素化的基本思路和方法。

所谓像素化，就是把一个图像看成是由一组像素点组合而成的。每个像素点负责描述图像上的一个点，并且带有这个点的基本绘图信息。那对于一张 800 像素宽、600 像素高的图片来说，整张图一共就有 48 万个像素点。

Canvas2D 以 4 个通道来存放每个像素点的颜色信息，每个通道是 8 个比特位，也就是 0~255 的十进制数值，4 个通道对应 RGBA 颜色的四个值。

像素处理实际上就是我们为了达到特定的视觉效果，用程序来处理图像上每个像素点。像素处理的应用非常广泛，能实现的效果也非常多。
* 实现灰度化图片：我们先将该图片的每个像素点的 R、G、B 通道的值进行加权平均，然后将这个值作为每个像素点新的 R、G、B 通道值。其中 R、G、B 是原图片中的 R、G、B 通道的色值，V 是加权平均色值，a、b、c 是加权系数，满足 (a + b + c) = 1。 除此以外，我们还可以对像素颜色做其他变换，比如增强或减弱某个通道的色值，改变颜色的亮度、对比度、饱和度、色相等等。
* 使用像素矩阵通用的改变像素信息：通过 4*5 颜色矩阵，让它的第一行决定红色通道，第二行决定绿色通道，第三行决定蓝色通道，第四行决定 Alpha 通道。那如果要改变一个像素的颜色效果，我们只需要将该矩阵与像素的颜色向量相乘就可以了。
* 使用高斯模糊对照片美颜：高斯模糊不是单纯根据颜色矩阵计算当前像素点的颜色值，而是会按照高斯分布的权重，对当前像素点及其周围像素点的颜色按照高斯分布的权重加权平均。这样做，我们就能让图片各像素色值与周围色值的差异减小，从而达到平滑，或者说是模糊的效果。高斯模糊是一个非常重要的平滑效果滤镜（Blur Filters）。高斯模糊不是处理单一像素，而是处理一个范围内的所有像素。

通过这种方式，实现局部放大的效果，感觉可以解决产品中 canvas 细节太多，部分细节无法清楚查看问题。

## 纹理和复杂滤镜
颜色滤镜是最基本的简单滤镜，因为简单滤镜里的每个像素都是独立的，所以它的处理结果**不依赖于其他像素点的信息**，因此应用起来也比较简单。**而高斯滤镜也就是平滑效果滤镜**，它是最基本的复杂滤镜。**复杂滤镜的处理结果不仅与当前像素有关，还与其周围的像素点有关**，所以应用起来很复杂。

还有一些简单滤镜的处理效果和像素点的坐标、外部环境（比如鼠标位置、时间）有关。
* 实现图片边缘模糊的效果。
* 可以利用像素处理实现图片融合。这种能叠加到其他照片上的图片，通常被称为**纹理**（Texture），叠加后的效果也叫做纹理效果。

纹理叠加能实现的效果非常多，所以它也是像素处理中的基础操作。不过，不管我们是用 Canvas 的 ImageData API 处理像素、应用滤镜还是纹理合成都有一个弊端，那就是我们必须循环遍历图片上的每个像素点。如果这个图片很大，这个计算量是相当大的。

这时我们需要 WebGL 帮忙，WebGL 通过运行着色器代码来完成图形的绘制和输出。其中，片元着色器负责处理像素点的颜色。

在 WebGL 中，我们会使用特殊的一种对象，叫做纹理对象（Texture）。我们将纹理对象作为一种特殊格式的变量，通过 uniform 传递给着色器，这样就可以在着色器中处理了。

纹理对象包括了整张图片的所有像素点的颜色信息，在着色器中，我们可以通过纹理坐标来读取对应的具体坐标处像素的颜色信息。纹理坐标是一个变量，类型是二维向量，x、y 的值从 0 到 1。

具体步骤
1. 创建纹理对象：这个步骤比较复杂，因为设置不同的参数可以改变我们在 Shader 中对纹理取色的行为，所以其中最复杂的是参数部分。
2. 设置纹理
3. 对纹理对象进行取色：在片元着色器中，使用 texture3D 函数获取纹理的颜色，一个是纹理单元的 uniform 变量，一个是要获取像素的坐标。
4. 实现滤镜
``` glsl
#ifdef GL_ES
precision highp float;
#endif

uniform sampler2D tMap;
uniform mat4 colorMatrix;
varying vec2 vUv;

void main() {
    vec4 color = texture2D(tMap, vUv);
    gl_FragColor = colorMatrix * vec4(color.rgb, 1.0);
    gl_FragColor.a = color.a;
}
```

实现粒子效果
```glsl
#ifdef GL_ES
precision highp float;
#endif

uniform sampler2D tMap;
uniform float uTime;
varying vec2 vUv;

float random (vec2 st) {
    return fract(sin(dot(st.xy,
                        vec2(12.9898,78.233)))*
        43758.5453123);
}

void main() {
    // 原始图片 1000*554，vec2(100, 55.4) 得到 10*10 大小的网格
    vec2 st = vUv * vec2(100, 55.4);
    // 随机一个偏移量
    vec2 uv = vUv + 1.0 - 2.0 * random(floor(st));
    // 引入 uTime 变量，用 mix 函数对偏移后的 uv 和原始的 vUv 相对于时间变化进行插值。
    vec4 color = texture2D(tMap, mix(uv, vUv, min(uTime, 1.0)));
    gl_FragColor.rgb = color.rgb;
    // 把 uTime 也和透明度关联起来
    gl_FragColor.a = color.a * uTime;
}
```

图像合成：比如对于在电影场景合成中比较常用的绿幕图片，我们就可以使用 shader 技术把它实时地合成到其他的图像上。
```glsl

#ifdef GL_ES
precision highp float;
#endif

uniform sampler2D tMap;
uniform sampler2D tCat;
varying vec2 vUv;

void main() {
    vec4 color = texture2D(tMap, vUv);
    vec2 st = vUv * 3.0 - vec2(1.2, 0.5);
    vec4 cat = texture2D(tCat, st);

    gl_FragColor.rgb = cat.rgb;
    // 色值替换
    if(cat.r < 0.5 && cat.g > 0.6) {
      gl_FragColor.rgb = color.rgb;
    }
    gl_FragColor.a = color.a;
}
```


资料
* [WebGL 纹理详解](https://zhuanlan.zhihu.com/p/68894334)