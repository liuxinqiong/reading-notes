## 简单动画
对于可视化展现来说，动画和 3D 都是用来强化数据表达，吸引用户的重要技术手段。它们往往比二维平面图形能够表达更复杂的数据，实现更吸引人的视觉效果。

动画的三种形式
* 固定帧动画：预先准备好要播放的静态图像，然后将这些图依次播放。固定帧动画实现起来非常简单，但它不适合生成需要动态绘制的图像，更适合在游戏等应用场景中，生成由美术提供现成图片的动画帧图像。
* 增量动画：在动态绘制图像的过程中，我们修改每一帧中某个或某几个属性的值，给它们一定的增量
  * 实现简单
  * 不太好控制动画的细节，比如动画周期、变化率、轨迹等等，所以这种方法只能用来实现简单动画
  * 增量动画定义的是状态变化。如果我们要在 shader 中使用动画，就只能采用后期处理通道来实现。但是后期处理通道要进行多次渲染，实现起来比较繁琐，而且性能开销也比较大。所以，更加复杂的轨迹动画，我们一般采用第三种方式，也就是通过**定义时间和动画函数**来实现
* 时序动画：在动态绘制图像的过程中，我们根据时间和动画函数计算每一帧中的关键属性值，然后更新这些属性
  * 时序动画的实现可以总结为三步：首先定义初始时间和周期，然后在 update 中计算当前经过时间和进度 p，最后通过 p 来更新动画元素的属性

时序动画-定义标准动画模型
```js
export class Timing {
  constructor({duration, iterations = 1} = {}) {
    this.startTime = Date.now();
    this.duration = duration;
    this.iterations = iterations;
  }

  get time() {
    return Date.now() - this.startTime;
  }

  get p() {
    const progress = Math.min(this.time / this.duration, this.iterations);
    return this.isFinished ? 1 : progress % 1;
  }

  get isFinished() {
    return this.time / this.duration >= this.iterations;
  }
}

export class Animator {
  constructor({duration, iterations}) {
    this.timing = {duration, iterations};
  }

  animate(target, update) {
    let frameIndex = 0;
    const timing = new Timing(this.timing);

    return new Promise((resolve) => {
      function next() {
        if(update({target, frameIndex, timing}) !== false && !timing.isFinished) {
          requestAnimationFrame(next);
        } else {
          resolve(timing);
        }
        frameIndex++;
      }
      next();
    });
  }
}

// demo
const blocks = document.querySelectorAll('.block');
const animator = new Animator({duration: 1000, iterations: 1.5});
(async function () {
    let i = 0;
    while(true) { // eslint-disable-next-line no-await-in-loop
        await animator.animate(blocks[i++ % 4], ({target, timing}) => {
            target.style.transform = `rotate(${timing.p * 360}deg)`;
        });
    }
}());
```

时序动画-插值与缓动函数
* 时序动画的好处就在于，它能更容易地控制动画的细节。
* 我们已知元素的**起始状态、结束状态和运动周期**。如果想要让它进行不规则运动，我们可以使用插值的方式来控制每一帧的展现

我们可以先实现一个匀速运动的方块，再通过插值与缓动函数来实现变速运动。
* 匀速运动：left = start * (1 - p) + end * p
* 如果是让方块非匀速运动，我们仍然可以使用线性插值，只不过要对插值参数 p 做一个函数映射。比如说，如果要让方块做初速度为 0 的匀加速运动，我们可以将 p 映射为 p^2。如果要让它做末速度为 0 的匀减速运动，我们可以将 p 映射为 p * (2 - p)。
* 那为了方便使用以及实现更多的效果，我们可以抽象出一个映射函数专门处理 p 的映射，这个函数叫做缓动函数（Easing Function）。

可以在前面实现过的 Timing 类中，直接增加一个缓动函数 easing。这样在获取 p 值的时候，我们直接用 this.easing(progress) 取代之前的 progress，就可以让动画变速运动了。
```js
export class Timing {
  constructor({duration, iterations = 1, easing = p => p} = {}) {
    this.startTime = Date.now();
    this.duration = duration;
    this.iterations = iterations;
    this.easing = easing;
  }

  get time() {
    return Date.now() - this.startTime;
  }

  get p() {
    const progress = Math.min(this.time / this.duration, this.iterations);
    return this.isFinished ? 1 : this.easing(progress % 1);
  }

  get isFinished() {
    return this.time / this.duration >= this.iterations;
  }
}
```

缓动函数有很多种，其中比较常用的是贝塞尔曲线缓动（Bezier-easing），准确地说，是三次贝塞尔曲线缓动函数。

## 用着色器实现像素动画
在 WebGL 中实现动画有所差别。
* 实现固定帧动画：在片元着色器中替换纹理坐标的方式，来非常简单地实现固定帧动画。
* 用着色器实现非固定帧动画：用 Shader 来实现非固定帧动画更加灵活，我们可以操作更多的属性，实现更丰富的效果。

我们知道，WebGL 有两种 Shader，分别是顶点着色器和片元着色器，它们都可以用来实现动画。

用顶点着色器实现非固定帧动画
```js
attribute vec2 a_vertexPosition;
attribute vec2 uv;

varying vec2 vUv;
uniform float rotation;

void main() {
  gl_PointSize = 1.0;
  vUv = uv;
  float c = cos(rotation);
  float s = sin(rotation);
  mat3 transformMatrix = mat3(
    c, s, 0,
    -s, c, 0,
    0, 0, 1
  );
  vec3 pos = transformMatrix * vec3(a_vertexPosition, 1);
  gl_Position = vec4(pos, 1);
}
```

用片元着色器实现非固定帧动画
* 当我们将时间参数 uTime 通过 uniform 传给着色器的时候，就是在实现动画
* 将坐标参数 uMouse 通过 uniform 传给着色器，就能实现响应鼠标动画

示例代码
```js
#ifdef GL_ES
precision highp float;
#endif

varying vec2 vUv;
uniform vec4 color;
uniform float rotation;

void main() {
  vec2 st = 2.0 * (vUv - vec2(0.5));
  float c = cos(rotation);
  float s = sin(rotation);
  mat3 transformMatrix = mat3(
    c, s, 0,
    -s, c, 0,
    0, 0, 1
  );
  vec3 pos = transformMatrix * vec3(st, 1.0);
  float d1 = 1.0 - smoothstep(0.5, 0.505, abs(pos.x));
  float d2 = 1.0 - smoothstep(0.5, 0.505, abs(pos.y));
  gl_FragColor = d1 * d2 * color;
}
```

> 一般来说，动画如果能使用顶点着色器实现，我们会尽量在顶点着色器中实现。因为在绘制一帧画面的时候，顶点着色器的运算量会大大少于片元着色器，所以使用顶点着色器消耗的性能更少。但是，在片元着色器中实现非固定帧动画也有优势。我们可以使用片元着色器的技巧，如重复、随机、噪声等等来绘制更加复杂的效果。

如何在着色器中实现缓动函数与非线性插值
```js
attribute vec2 a_vertexPosition;
attribute vec2 uv;

varying vec2 vUv;
uniform vec2 translation;

void main() {
  gl_PointSize = 1.0;
  vUv = uv;
  mat3 transformMatrix = mat3(
    1, 0, 0,
    0, 1, 0,
    translation, 1
  );
  vec3 pos = transformMatrix * vec3(a_vertexPosition, 1);
  gl_Position = vec4(pos, 1);
}

// 具体使用
renderer.uniforms.color = [1, 0, 0, 1];
renderer.uniforms.translation = [-0.5, 0];
const animator = new Animator({duration: 2000});
animator.animate(renderer, ({target, timing}) => {
    target.uniforms.translation = [-0.5 * (1 - timing.p) + 0.5 * timing.p, 0];
});
```

我们还可以通过缓动函数来实现非匀速运动。而且我们既可以将缓动函数用 JavaScript 计算，也可以直接将缓动函数放在 Shader 中。将时间 uTime 参数传入 Shader，然后在 Shader 中加入缓动函数。因为 Shader 是在 GPU 中运算的，所以所有顶点都是被并行处理的。因此，通常情况下，我们在顶点着色器中执行缓动函数会更快。

不过，**直接用 JavaScript 计算和放在顶点着色器里计算，差别也不是很大，但如果把它放在片元着色器里计算，因为要把每个像素点都计算一遍，所以性能消耗反而更大一些**。那我们为什么还要在着色器中计算 easing 呢？这是因为，我们不仅可以利用 easing 控制动画过程，还可以在片元着色器中用 easing 来实现非线性的插值。

在正常情况下，顶点着色器定义的变量在片元着色器中，都会被线性插值。

如何在片元着色器中实现随机粒子动画：使用片元着色器还可以实现非常复杂的图形动画，包括粒子动画、网格动画以及网格噪声动画等等。针对粒子效果，因为实现的过程中会涉及非常多点的运算，如果不用 shader，我们几乎是无法完成的。

## WebGL 绘制 3D 物体
学习矩阵和法向量在三维空间的应用。

一个立方体有 8 个顶点，这 8 个顶点能组成 6 个面。在 WebGL 中，我们就需要用 12 个三角形来绘制它。如果每个面的属性相同，我们就可以复用 8 个顶点来绘制。而**如果属性不同，比如每个面要绘制成不同的颜色，或者添加不同的纹理图片，我们还得把每个面的顶点分开**。这样的话，我们一共需要 24 个顶点。

绘制 3D 图形与绘制 2D 图形有一点不一样，那就是我们必须要开启深度检测和启用深度缓冲区。在 WebGL 中，我们可以通过 `gl.enable(gl.DEPTH_TEST)`，来开启深度检测。而且，我们在清空画布的时候，也要用 `gl.clear(gl.COLOR_BUFFER_BIT | gl.DEPTH_BUFFER_BIT);`，来同时清空颜色缓冲区和深度缓冲区。**启动和清空深度检测和深度缓冲区这两个步骤**，是这个过程中非常重要的一环。

实际上，WebGL 默认的剪裁坐标的 z 轴方向，的确是朝内的。也就是说，WebGL 坐标系就是一个左手系而不是右手系。但是，基本上所有的 WebGL 教程，也包括我们前面的课程，一直都在说 WebGL 坐标系是右手系，这又是为什么呢？这是因为，规范的直角坐标系是右手坐标系，符合我们的使用习惯。因此，一般来说，不管什么图形库或图形框架，在绘图的时候，都会默认将坐标系从左手系转换为右手系。

将 WebGL 的坐标系从左手系转换为右手系。关于坐标转换，我们可以通过齐次矩阵来完成。将左手系坐标转换为右手系，实际上就是将 z 轴坐标方向反转，对应的齐次矩阵如下：
```js
[
  1, 0, 0, 0,
  0, 1, 0, 0,
  0, 0, -1, 0,
  0, 0, 0, 1
]
```

除了构造顶点的位置和颜色信息，我们还可以构造几何体的其他信息，其中一种比较有用的信息是顶点的法向量信息。那什么是法向量呢？法向量表示每个顶点所在的面的法线方向，在 3D 渲染中，我们可以通过**法向量来计算光照、阴影、进行边缘检测**等等。

因为几何体是由三角网格构成的，而法线是垂直于三角网格的线，如果要计算法线，我们可以借助三角形的顶点，使用向量的叉积定理来求。我们假设在一个平面内，有向量 a 和 b，n 是它们的法向量，那我们可以得到公式：n = a X b。

在 shader 中实现点光源效果。因为我们在 shader 中，会使用模型矩阵对顶点进行变换，所以在片元着色器中，我们拿到的是变换后的顶点坐标，这时候，如果我们要应用法向量，需要对法向量也进行变换，我们可以通过一个矩阵来实现，这个矩阵叫做法向量矩阵（NormalMatrix）。它是模型矩阵的逆转置矩阵，不过它非常特殊，是一个 3X3 的矩阵（mat3），而像模型矩阵、投影矩阵等等矩阵都是 4X4 的。

## 添加相机，用透视原理对物体进行投影
在 WebGL 的三维世界任意位置上有一个相机，它可以用**一个三维坐标（Position）和一个三维向量方向（LookAt Target）**来表示。

在初始情况下，相机的参考坐标和世界坐标是重合的。但是，当我们移动或者旋转相机的时候，相机的参考坐标和世界坐标就不重合了。

而我们最终要在 Canvas 画布上绘制出的是，**以相机为观察者的图形，所以我们就需要用一个变换，将世界坐标转换为相机坐标**。这个变换的矩阵就是视图矩阵（ViewMatrix）。

计算视图矩阵比较简单的一种方法是，我们先计算相机的模型矩阵，然后对矩阵使用 lookAt 函数，这样我们得到的矩阵就是视图矩阵的逆矩阵。然后，我们再对这个逆矩阵求一次逆，就可以得到视图矩阵了。

我们通过代码来理解如下
```js
function updateCamera(eye, target = [0, 0, 0]) {
  const [x, y, z] = eye;
  const m = new Mat4(
    1, 0, 0, 0,
    0, 1, 0, 0,
    0, 0, 1, 0,
    x, y, z, 1,
  );
  const up = [0, 1, 0];
  m.lookAt(eye, target, up).inverse();
  renderer.uniforms.viewMatrix = m;
}
```

**WebGL 的默认坐标范围是从 -1 到 1 的**。也就是说，只有当图像的 x、y、z 的值在 -1 到 1 区间内才会被显示在画布上，而在其他位置上的图像都会被剪裁掉。为了让图形在剪裁空间中正确显示，我们不能只反转 z 轴，还需要将图像从三维空间中投影到剪裁坐标内。那么问题来了，图像是怎么被投影到剪裁坐标内的呢？一般来说，投影有两种方式，分别是**正投影与透视投影**。

首先是正投影，它又叫做平行投影。正投影是将物体投影到一个长方体的空间（又称为视景体），并且无论相机与物体距离多远，投影的大小都不变。

而透视投影则更接近我们的视觉感知。它投影的规律是，离相机近的物体大，离相机远的物体小。与正投影不同，正投影的视景体是一个长方体，而透视投影的视景体是一个棱台。

知道了不同投影方式的特点，我们就可以根据投影方式和给定的参数来计算投影矩阵了。其中，ortho 是计算正投影的函数，它的参数是视景体 x、y、z 三个方向的坐标范围，它的返回值就是投影矩阵。而 perspective 是计算透视投影的函数，它的参数是近景平面 near、远景平面 far、视角 fov 和宽高比率 aspect，返回值也是投影矩阵。
```js
// 计算正投影矩阵
function ortho(out, left, right, bottom, top, near, far) {
   let lr = 1 / (left - right);
   let bt = 1 / (bottom - top);
   let nf = 1 / (near - far);
   out[0] = -2 * lr;
   out[1] = 0;
   out[2] = 0;
   out[3] = 0;
   out[4] = 0;
   out[5] = -2 * bt;
   out[6] = 0;
   out[7] = 0;
   out[8] = 0;
   out[9] = 0;
   out[10] = 2 * nf;
   out[11] = 0;
   out[12] = (left + right) * lr;
   out[13] = (top + bottom) * bt;
   out[14] = (far + near) * nf;
   out[15] = 1;
   return out;
}

// 计算透视投影矩阵
function perspective(out, fovy, aspect, near, far) {
   let f = 1.0 / Math.tan(fovy / 2);
   let nf = 1 / (near - far);
   out[0] = f / aspect;
   out[1] = 0;
   out[2] = 0;
   out[3] = 0;
   out[4] = 0;
   out[5] = f;
   out[6] = 0;
   out[7] = 0;
   out[8] = 0;
   out[9] = 0;
   out[10] = (far + near) * nf;
   out[11] = -1;
   out[12] = 0;
   out[13] = 0;
   out[14] = 2 * far * near * nf;
   out[15] = 0;
   return out;
}
```

3D 绘制几何体的基本数学模型，也就是 3D 绘图的标准模型。这个标准模型一共有四个矩阵，它们分别是：
* 投影矩阵、视图矩阵（ViewMatrix）、模型矩阵（ModelMatrix）、法向量矩阵（NormalMatrix）
* 前三个矩阵用来计算最终显示的几何体的顶点位置，第四个矩阵用来实现光照等效果

## 使用放射变化来旋转移动物体
我们可以使用齐次矩阵来表示三维仿射变换，通过引入一个新的维度，就可以把仿射变换转换为齐次矩阵的线性变换了。
```js
M’=[M 0​
    0 1​]
```

总之，对于三维的仿射变换来说，平移和缩放都只是增加一个 z 分量，这和二维放射变换没有什么不同。但对于物体的旋转变换，三维就要比二维稍微复杂一些了。因为二维旋转只有一个参考轴，就是 z 轴，所以二维图形旋转都是围绕着 z 轴的。但是，三维物体的旋转却可以围绕 x、y、z，这三个轴其中任意一个轴来旋转。

**如果我们使用旋转变换矩阵 Ry、Rx、Rz 分别表示绕 y/x/z 轴的旋转，这三个旋转矩阵分别表示几何体绕 y 轴、x 轴、z 轴转过 α、β、γ 角。而这三个角，就叫做欧拉角**。

那什么是欧拉角呢？欧拉角是描述三维物体在空间中取向的标准数学模型，也是航空航天普遍采用的标准。对于在三维空间里的一个参考系，任何坐标系的取向，都可以用三个欧拉角来表示。

如何理解万向节锁？
* 当我们分别改变飞机的 alpha、beta、theta 值时，飞机会做出对应的姿态调整，包括偏航（改变 alpha）、翻滚（改变 beta）和俯仰（改变 theta）。
* 但是如果我们将 beta 固定在正负 90 度，改变 alpha 和 theta，不管改变 alpha 还是改变 theta，飞机都绕着 y 轴旋转，始终处于一个平面上。也就是说，本来飞机姿态有 x、y、z 三个自由度，现在 y 轴被固定了，只剩下两个自由度了，这就是万向节锁。

万向节锁，并不是真的“锁”住。而是在特定的欧拉角情况下，姿态调整的自由度丢失了。而且，只要是欧拉角，不管我们使用哪一种顺规，万向节锁都会存在。这该怎么解决呢？要避免万向节锁的产生，我们只能使用其他的数学模型，来代替欧拉角描述几何体的旋转。其中一个比较好的模型是四元数（Quaternion）。

四元数是一种高阶复数，一个四元数可以表示为：q=w+xi+yj+zk。其中，i、j、k 是三个虚数单位，w 是标量，它们满足 i^2=j^2=k^2=ijk=−1。如果我们把 xi+yj+zk 看成是一个向量，那么四元数 q 又可以表示为 q=(v,w)，其中 v 是一个三维向量。

我们可以用单位四元数来描述 3D 旋转。所谓单位四元数，就是其中的参数满足 x^2+y^2+z^2+w^2=1。推导比较复杂，我们只需要记住单位四元数对应的旋转矩阵即可。

与欧拉角相比，四元数没有万向节死锁的问题。而且与旋转矩阵相比，**四元数只需要四个分量就可以定义，模型上更加简洁。但是，四元数相对来说没有旋转矩阵和欧拉角那么直观**。

四元数有一个常见的用途是用来处理轴角。**所谓轴角，就是在三维空间中，给定一个由单位向量表示的轴，以及一个旋转角度 ⍺，以此来表示几何体绕该轴旋转 ⍺ 角。绕单位向量 u 旋转 ⍺ 角，对应的四元数可以表示为：`q=(usin(⍺/2),cos(⍺/2))`**。

## 如何模拟光照让3D场景更逼真
物体的光照效果是由光源、介质（物体的材质）和反射类型决定的，而反射类型又由物体的材质特点决定。在 3D 光照模型中，根据不同的光源特点，我们可以将光源分为 4 种不同的类型，分别是环境光（Ambient Light）、平行光（Directional Light）、点光源（Positional Light）和聚光灯（Spot Light）。而物体的反射类型，则分为漫反射和镜面反射两种。

那什么是环境光呢？环境光就是指物体所在的三维空间中天然的光，它充满整个空间，在每一处的光照强度都一样。环境光没有方向，所以，**物体表面反射环境光的效果，只和环境光本身以及材质的反射率有关**。

与环境光不同，平行光是朝着某个方向照射的光，它能够照亮几何体的一部分表面。平行光除了颜色这个属性之外，还有方向，它属于有向光。有向光在与物体发生作用的时候，根据物体的材质特性，会产生两种反射，一种叫做漫反射（Diffuse reflection），另一种叫做镜面反射（Specular reflection），而一个物体最终的光照效果，是漫反射、镜面反射以及我们前面说的环境光叠加在一起的效果。

那我们该如何让 3D 物体呈现出，平行光照射下的颜色效果呢？首先，我们在顶点着色器中添加一道平行光。具体来说就是传入一个 directionalLight 向量。为什么是顶点着色器呢？因为，**我们在顶点着色器中计算光线的方向，需要运算的次数少，会比在片元着色器中计算的性能要好很多**。

点光源顾名思义，就是指空间中某一点发出的光，与方向光不同的是，点光源不仅有方向属性，还有位置属性。因此计算点光源的光照，我们要先根据光源位置和物体表面相对位置来确定方向，然后再和平行光一样，计算光的方向和物体表面法向的夹角。

对于平行光来说，只要法向量相同，方向就相同，所以我们可以直接在顶点着色器中计算方向。但点光源因为其方向与物体表面的相对位置有关，所以我们不能在顶点着色器中计算，需要在片元着色器中计算。

真实世界中，点光源的光照强度会随着空间的距离增加而衰减。所以，为了实现更逼真的效果，我们必须要把光线衰减程度也考虑进去。光线的衰减程度，我们一般用衰减系数表示。衰减系数等于一个常量 d0​（通常为 1），除以衰减函数 p。

与点光源相比，聚光灯增加了方向以及角度范围，只有在这个范围内，光线才能照到。那该如何判断坐标是否在角度范围内呢？我们可以根据法向量与光线方向夹角的余弦值来判断坐标是否在夹角内。

什么是镜面反射呢？如果若干平行光照射在表面光滑的物体上，反射出来的光依然平行，这种反射就是镜面反射。镜面反射的性质是，入射光与法线的夹角等于反射光与法线的夹角。

越光滑的材质，它的镜面反射效果也就越强。最直接的表现就是物体表面会有闪耀的光斑，也叫镜面高光。环境光因为没有方向，所以不参与镜面反射。剩下的平行光、点光源、聚光灯这三种光源，都是能够产生镜面反射的有向光。

如何实现有向光的镜面反射？镜面反射需要同时考虑光的入射方向以及相机也就是观察者所在的方向。
* 第一步：求出反射光线的方向向量
* 第二步：我们要根据相机位置计算视线与反射光线夹角的余弦，用到原理是向量的点乘
* 第三步：我们使用系数和指数函数设置镜面反射强度。指数越大，镜面越聚焦，高光的光斑范围就越小
* 第四步：我们将漫反射和镜面反射结合起来，就会让距离光源近的物体上，形成光斑。

如何实现完整的 Phong 反射模型。源码级别的实现分析。

## 使用法线贴图模拟真实物体表面
真实世界中，大部分物体的表面都是凹凸不平的，这肯定会影响光照的反射效果。因此，只有处理好物体凹凸表面的光照效果，我们才能更加真实地模拟物体表面。在图形学中就有一种对应的技术，叫做**法线贴图**。

如果我们想在立方体的表面贴上凹凸的花纹。我们可以加载一张法线纹理。实际上，**这张纹理图片保存的是几何体表面的每个像素的法向量数据**。正常情况下，光滑立方体每个面的法向量是固定的，但如果表面有凹凸的花纹，那不同位置的法向量就会发生变化。在切线空间中，因为法线都偏向于 z 轴，也就是法向量偏向于 (0,0,1)，所以转换成的法线纹理就偏向于蓝色。如果我们根据花纹将每个点的法向量都保存下来，就会得到上面那张法线纹理的图片。

如何理解切线空间？
* 切线空间（Tangent Space）是一个特殊的坐标系，它是由几何体顶点所在平面的 uv 坐标和法线构成的。
* 切线空间的三个轴，一般用 T (Tangent)、B (Bitangent)、N (Normal) 三个字母表示，所以切线空间也被称为 TBN 空间。其中 T 表示切线、B 表示副切线、N 表示法线。
* 对于大部分三维几何体来说，因为每个点的法线不同，所以它们各自的切线空间也不同。

而计算切线和副切线，要比计算法线复杂得多，不过，因为数学推导过程比较复杂，我们只要记住结论就可以了。

我们来回忆一下，怎么计算几何体三角形网格的法向量。假设一个三角形网格有三个点 v1、v2、v3，我们把边 v1v2 记为 e1，边 v1v3 记为 e2，那三角形的法向量就是 e1 和 e2 的叉积表示的归一化向量。
```js
function getNormal(v1, v2, v3) {
  const e1 = Vec3.sub(v2, v1);
  const e2 = Vec3.sub(v3, v1);
  const normal = Vec3.cross(e1, e1).normalize();
  return normal;
}
```

扩展：WebGL2.0 写法
* WebGL2.0 对应 OpenGL ES3.0
* 声明 #version 300 es 表示这段代码是 OpenGL ES3.0 的，然后我们可以用 in 和 out 对应变量的输入和输出，来取代之前的 attribute 和 varying

构建 TBN 矩阵来计算法向量：有了 tang 和 bitang 之后，我们就可以构建 TBN 矩阵来计算法线了。这里的 TBN 矩阵的作用，就是将法线贴图里面读取的法向量数据，转换为对应的切线空间中实际的法向量。这里的切线空间，实际上对应着我们观察者（相机）位置的坐标系。

法线贴图就是根据法线纹理中保存的法向量数据以及 TBN 矩阵，将实际的法线计算出来，然后用实际的法线来计算光照的反射。具体点来说，要实现法线贴图，我们需要通过顶点数据计算几何体的切线和副切线，然后得到 TBN 矩阵，用 TBN 矩阵和法线纹理数据来计算法向量，从而完成法线贴图。

使用**偏导数**来实现法线贴图：构建 TBN 矩阵求法向量的方法还是有点麻烦。事实上，还有一种更巧妙的方法，不需要用顶点数据计算几何体的切线和副切线，而是直接用坐标插值和法线纹理来计算。

代码如下
```js
vec3 getNormal() {
  // Fdx、dFdy 是 GLSL 内置函数，可以求插值的属性在 x、y 轴上的偏导数。偏导数其实就代表插值的属性向量在 x、y 轴上的变化率，或者说曲面的切线。
  vec3 pos_dx = dFdx(vPos.xyz);
  vec3 pos_dy = dFdy(vPos.xyz);
  vec2 tex_dx = dFdx(vUv);
  vec2 tex_dy = dFdy(vUv);

  // 将顶点坐标曲面切线与 uv 坐标的切线求叉积，就能得到垂直于两条切线的法线。
  vec3 t = normalize(pos_dx * tex_dy.t - pos_dy * tex_dx.t);
  vec3 b = normalize(-pos_dx * tex_dy.s + pos_dy * tex_dx.s);
  // 在 x、y 两个方向上求出的两条法线，就对应 TBN 空间的切线 tang 和副切线 bitang。然后，我们使用偏导数构建 TBN 矩阵
  mat3 tbn = mat3(t, b, normalize(vNormal));

  vec3 n = texture(tNormal, vUv).rgb * 2.0 - 1.0;
  // 把 TBN 矩阵左乘从法线纹理中提取出的值，就可以计算出对应的法向量了。
  return normalize(tbn * n);
}
```

这样做的好处是，我们不需要预先计算几何体的 tang 和 bitang 了。不过在片元着色器中计算偏导数也有一定的性能开销，所以各有利弊，我们可以根据不同情况选择不同的方案。

法线贴图是一种经典的图形学技术，可以用来给物体表面增加细节，让我们实现的效果更逼真。具体来说，法线贴图是用一张图片来存储表面的法线数据。这张图片叫做法线纹理，它上面的每个像素对应一个坐标点的法线数据。要想使用法线纹理的数据，我们还需要构建 TBN 矩阵。这个矩阵通过向量、矩阵乘法将法线数据转换到世界坐标中。

构建 TBN 矩阵我们有两个方法，一个是根据几何体顶点数据来计算切线（Tangent）、副切线（Bitangent），然后结合法向量一起构建 TBN 矩阵。另一个方法是使用偏导数来计算，这样我们就不用预先在顶点中计算 Tangent 和 Bitangent 了。两种方法各有利弊，我们可以根据实际情况来合理选择。

## 如何绘制带宽度的线
在 Canvas2D 中，要绘制带宽度的曲线非常简单，我们直接设置上下文对象的 lineWidth 属性就行了。但在 WebGL 中，绘制带宽度的曲线是一个难点。

用 Canvas2D 绘制曲线非常简单。这是为什么呢？因为 Canvas2D 提供了相应的 API，能够绘制出不同宽度、具有特定**连线方式 lineJoin**和**线帽形状 lineCap**的曲线。

曲线是由线段连接而成的，两个线段中间转折的部分，就是 lineJoin。如果线宽只有一个像素，那么连接处没有什么不同的形式，就是直接连接。但如果线宽超过一个像素，那么连接处的缺口，就会有不同的填充方式，而这些不同的填充方式，就对应了不同的 lineJoin。

什么是 lineCap 呢？lineCap 就是指曲线头尾部的形状，它有三种类型。第一种是 square，方形线帽，它会在线段的头尾端延长线宽的一半。第二种 round 也叫圆弧线帽，它会在头尾端延长一个半圆。第三种是 butt，就是不添加线帽。

**通过挤压 (extrude) 曲线绘制有宽度的曲线**
* 通过将曲线的顶点沿法线方向向两侧移出，让 1 个像素的曲线变宽。
* 因为折线两个端点的挤压只和一条线段的方向有关，而转角处顶点的挤压和相邻两条线段的方向都有关，所以顶点移动的方向，我们要分两种情况讨论。
* 首先，是折线的端点。假设线段的向量为（x, y），因为它移动方向和线段方向垂直，所以我们只要沿法线方向移动它就可以了。根据垂直向量的点积为 0，我们很容易得出顶点的两个移动方向为（-y, x）和（y, -x）
* 端点挤压方向确定了，接下来要确定转角的挤压方向了，我们假设有折线 abc，b 是转角。我们延长 ab，就能得到一个单位向量 v1，反向延长 bc，可以得到另一个单位向量 v2，那么挤压方向就是向量 v1+v2 的方向，以及相反的 -(v1+v2) 的方向。
* 首先是折线端点的挤压长度，它等于 lineWidth 的一半。
* 转角的挤压长度就比较复杂了，我们需要再计算一下。

具体代码如下
```js
function extrudePolyline(gl, points, {thickness = 10} = {}) {
  const halfThick = 0.5 * thickness;
  const innerSide = [];
  const outerSide = [];

  // 构建挤压顶点
  for(let i = 1; i < points.length - 1; i++) {
    const v1 = (new Vec2()).sub(points[i], points[i - 1]).normalize();
    const v2 = (new Vec2()).sub(points[i], points[i + 1]).normalize();
    const v = (new Vec2()).add(v1, v2).normalize(); // 得到挤压方向
    const norm = new Vec2(-v1.y, v1.x); // 法线方向
    const cos = norm.dot(v);
    const len = halfThick / cos;
    if(i === 1) { // 起始点
      const v0 = new Vec2(...norm).scale(halfThick);
      outerSide.push((new Vec2()).add(points[0], v0));
      innerSide.push((new Vec2()).sub(points[0], v0));
    }
    v.scale(len);
    outerSide.push((new Vec2()).add(points[i], v));
    innerSide.push((new Vec2()).sub(points[i], v));
    if(i === points.length - 2) { // 结束点
      const norm2 = new Vec2(v2.y, -v2.x);
      const v0 = new Vec2(...norm2).scale(halfThick);
      outerSide.push((new Vec2()).add(points[points.length - 1], v0));
      innerSide.push((new Vec2()).sub(points[points.length - 1], v0));
    }
  }
  // 向内和向外挤压的点现在分别保存在 innerSide 和 outerSide 数组中，接下来构建 geometry
  const count = innerSide.length * 4 - 4;
  const position = new Float32Array(count * 2);
  const index = new Uint16Array(6 * count / 4);

  // 创建 geometry 对象
  for(let i = 0; i < innerSide.length - 1; i++) {
    const a = innerSide[i],
      b = outerSide[i],
      c = innerSide[i + 1],
      d = outerSide[i + 1];

    const offset = i * 4;
    index.set([offset, offset + 1, offset + 2, offset + 2, offset + 1, offset + 3], i * 6);
    position.set([...a, ...b, ...c, ...d], i * 8);
  }

  return new Geometry(gl, {
    position: {size: 2, data: position},
    index: {data: index},
  });
}
```

## 如何实现简单的可视化图表
z-fighting 是 3D 绘图中的一个常见问题，所以我再多解释一下。在 WebGL 中绘制 3D 物体，一般我们开启了深度检测之后，引擎会自动计算 3D 物体的深度，让离观察者很近的物体面，把离观察者比较远和背对着观察者的物体面遮挡住。那具体是怎么遮挡的呢？其实是根据物体在相机空间中的 z 坐标来判断的。

但有一种特殊情况，就是两个面的 z 坐标相同，又有重叠的部分。这时候，引擎就可能一会儿先渲染 A 面，过一会儿又先去渲染 B 面，这样渲染出来的内容就出现了“闪烁”现象，这就是 z-fighting。

z-fighting 有很多解决方法，比如可以人为指定一下几何体渲染的次序，或者，就是让它们的坐标不要完全相同，在上面的例子里，我们就采用了让坐标不完全相同的处理办法。