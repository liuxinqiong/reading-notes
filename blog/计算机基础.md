重要的基础知识

## 具体内容
信息的表示和处理
* 计算机如何表示整数：有符号数和无符号数，尤其是如何用补码表示负数，数字的取值范围。
* 计算机如何表示浮点数，为什么小数的二进制表示法只能近似表示十进制小数。
* 数值的转换、移位

> 搞不清这些表示和运算，在编程中就会遇到一些稀奇古怪的问题。

从汇编层面理解程序的执行
* 顺序、分支、循环、函数调用、数组、结构体等在汇编层面是怎么实现的，寄存器和内存是怎么使用的。
* 理解了这些其实也就理解了冯诺依曼计算机体系结构
* 理解了栈帧，就能理解函数调用的本质，递归，以及尾递归的实现。还有安全相关的概念，如缓冲区溢出这个臭名昭著的漏洞及其防范办法。

进程和线程
* 进程的地址空间，代码在哪里，堆在哪里，栈在哪里。
* 准确理解进程和线程之间的关系，为什么说进程是拥有资源的基本单位，线程是 CPU 调度的基本单位？
* 进程切换和线程切换之间的区别和联系。
* 如何创建，执行，有哪些状态，状态之间的转换。由此会涉及到并发和并行，线程之间的竞争和合作。
* 锁的本质（硬件层面），乐观锁，悲观锁，死锁等问题。
* 线程的实现方式，用户级线程和内核级线程的对应方式。

存储器的层次结构
* CPU 超级快，内存比较快，硬盘非常慢，网络更慢
* 人类想了很多办法试图去弥补这个差异：**多线程，缓存，异步，多路复用，硬件层面的 DMA**。

数据结构和算法
* 理解了 B+ Tree 才能理解 MySQL 的 InnoDB 的索引
* 理解了索引才能更好地优化查询

计算机网络
* HTTP 协议
* TCP、UDP，尤其是 TCP 可靠传输的原理：如何在一个不可靠的网络中进行可靠的传输， 这是无数前辈总结的经验，一定得掌握
* 要理解什么是通信协议，也许某一天你自己就需要定制一个协议来传输数据。
* 分组交换是什么意思？ 协议分层的本质是什么？ 什么叫无状态的协议？
* Socket 相关的编程更是重点，尤其是涉及到服务器端高并发的时候，如何维持和处理这些海量的 socket， epoll 等技术就得上场了。
* 重要的 HTTPS 的基本原理，也是网络安全的精华所在：对称加密，非对称加密，消息摘要，数字证书，中间人攻击。

数据库
* 关系模型
* 范式
* SQL
* 索引
* 事务

分布式的基础知识
* RPC，消息队列等
* 负载均衡的原理
* CAP 原理，BASE 原理，幂等性，一致性模型（强一致性，最终一致性.....）和相关协议(两阶段提交，Raft，Paxos......)
* 数据分片：取模算法，一致性 Hash，虚拟桶

基本的设计思想
* 正交：各个概念之间可以独立变化
* 抽象：抛弃细节，找到本质和共性
* 分层：我只想和我的邻居打交道， 如网络协议，Web 应用开发。
* 分而治之：大事化小，小事化了，架构设计必备。

> 《深入理解计算机系统》一书中提到：“指令集是对 CPU 的抽象， 文件是对输入/输出设备的抽象， 虚拟存储器是对程序存储的抽象， 进程是对一个正在运行的程序的抽象， 而虚拟机是对整个计算机（包括操作系统、处理器和程序）的抽象。 如果你对这句话透彻理解了，说明对计算机系统的认识已经很深刻了。

## 锁
关于锁
* 原子操作：指不会被线程调度打断的操作，操作一旦开始，就会一直运行到结束，中间不会有上下文切换。数据库事务中的 ACID 中的 A 指的就是原子性。
* 原子操作可以分为软件层面和硬件层面，硬件层面的原子操作又分为单核 CPU 和多核 CPU，单核 CPU 中，能够在一个指令中完成的操作都可以看做原子操作，因为中断只发生在指令切换中。多核 CPU 情况下，runtime 运行着多个独立 CPU，即使单个指令的操作，也可能被干扰。原子操作在硬件层面有所实现，比如 x86 架构下，CPU 提供了 HLOCK pin 引线，允许 CPU 在执行某个指令时拉低 HLOCK pin 引线的电位，直到指令执行完毕才放开。锁住了总线其他核就无法继续执行指令，此时就可以保证多核处理器的原子性
* CAS 用来保证加锁过程中的原子性，会比较地址指针是否为 old，为 old 说明操作期间没有被打断，就地址值替换为 new，返回 true,不为 old, 代表操作期间被其他线程打断了，返回 false。

## 浮点数
计算机的本质决定了它是一个二进制的世界，人类熟悉的十进制数字需要转行成二进制才能被计算机处理。但是这个转化的过程却会遇到问题。从漫画中可以看出十进制整数都能精确地转化为二进制表示，但是十进制小数却并不一定。

对于工程计算和科学计算，一个非常近似的二进制小数是可以满足要求的，但是在商业计算尤其是金融领域，必须要精确地表示，精确地计算，这个时候就不能直接使用 float，double 等类型了，需要用一个工具类如 BigDecimal 来进行处理。

拼凑法进行转换
* 整数部分和小数部分，各自对应者一个工具箱，分别存储着 2^n 和 2^-n 方对应的二进制值。当十进制数进来时，查表看有没有，没有则查找最近的，然后不断进行拼凑
* 对于十进制整数，只要能表示层 2^n 次方的和，就能拼凑出来。十进制小数只要能表示成 2^-n 的和，也能拼凑，但有不少十进制小数不满足这个性质
* 解决不精准问题：把小数转换成整数，记录下小数点后面有几位小数，然后通过整数进行运算。这就是 BigDecimal 的原理

对于浮点数的存储制定了规范，比如 IEEE 754
* 定点数方案：比如针对 32 位的存储，首位（符号为）+ 8 位整数位 + 23 位小数位，小数点固定在了具体的位置，因此称为定点数。但对于整数部分和小数部分位数的分配是个问题，整数部分大，能表示的范围大，小数部分大，那数据就更精确。所以很难选择，不是完美的解决方案
* 科学记数法：368.79 表示为 3.6879 * 10^2
* 浮点数就是利用指数达到小数点浮动的效果，从而灵活的表达更大范围内的数。不过对于同一个浮点数，也有很多表达方式，取决于你的指数取多大，由于其多样性，因此我们需要特定的标准
* IEEE 754 标准，有单精度（32）和双精度（64）
  * 科学表示为：(+ or - ) 1.(mantissa) * 2 ^ exponent，比如 5.8 表示成 1.45 * 2 ^ 2
  * 针对 5.8：符号为 s = 0；指数部分需要注意，指数也有正负之分，既要用 8 为表示正数，又要能表示负数，因此分开使用 0-127 表示负数，128-255 表示正数。127 被称为偏置值。所以 exponent = 127 + 2 = 129。尾数 mantissa 是 0.45，需要转化成二进制，不断的乘 2，去结果的整数部分就行，有时候这一部会出现无限循环，这时候取到要求的 23 位就行，可见浮点数是不精确的

## 怎么学习
一种更加有效的办法是从工作中用到的知识点出发，从这个知识点向外扩展，由点到线，由线到面，然后让各个层次都连接起来，形成一个立体的网络。

切记，学习是一个螺旋上升的过程，**想要上升就得深度思考，多问几个为什么**。

## 来源
* [那些让你起飞的基础知识](https://mp.weixin.qq.com/s/Rt9Kn8BoWVfxdBlYdpFDCQ)