## 我是一个线程

线程优先级

执行时间片：每个线程只能在CPU上运行一段时间，到了时间就得让别人用了。

线程状态：等待，就绪，运行反复轮转

线程池

规则
1. 不知道什么时候会被挑中执行
2. 执行的过程中随时可能被打断，让出CPU
3. 一旦出现硬盘、数据库这样耗时的操作，也得让出CPU去等待
4. 数据来了，你也不一定能马上执行，还得等着CPU挑选

数据库连接池

基于原数据的数据修改，需要加锁操作，比如存款取款

死锁的情况：比如转账操作，需要对两个资源（账户）进行加锁，如果不幸别的线程也需要这两个资源，一旦各执一锁，就会出现死锁

如果避免死锁：构造一个方法，用来计算资源的大小，计算出来后，永远按照大到小的方式来获得锁。

> 所谓资源的大小，其实就是把这个资源变成一个数来比较，例如，可以用字符串的hashcode来比较

谨记：多个资源加锁要牢记，一定要按照Boss的算法比较大小，然后从最大的开始加锁

### 扩展
物理核数量=cpu数(机子上装的cpu的数量)*每个cpu的核心数

虚拟核：通过超线程技术，用一个物理核模拟多个核

一个核同一时间只能执行一个线程

串行：多个任务，执行时一个执行完再执行另一个。

并发：多个线程在单个核心运行，同一时间一个线程运行，系统不停切换线程，看起来像同时运行，实际上是线程不停切换。

并行：每个线程分配给独立的核心，线程同时运行。

## TCP/IP

失败重传、拆分编号

不需要事先建立真正的连接通道，每个编号小块走的路也可能不一样，每个小块也可能不按次序（失序）到达。

> 中间节点并不承诺提供可靠的连接通道，物资完全可能失序、重复、甚至丢失，所谓可靠的传输完全由两个端点来实现

TCP连接：TCP连接是虚拟连接，连接的状态信息并不会在路上保存，连接的状态信息是在两端维持的。

三次握手：主要验证双方的收发能力没问题，就证明连接是通的，就可以正式发货了。假设B端与S端通信
1. 第一次握手，B端发送数据包，S端收到了，S端就会明白B端的发送能力和自己的接收能力没问题
2. 第二次握手，S端发送数据包，B端收到了，B端就会明白自己的发送和接受能力都没问题，S端的发送和接受能力也没问题，但是S端还不清楚自己的发送能力如何，所以需要第三次握手
3. 第三次握手，B端发送，S端收到了，这次的目的就是消除S端对自己的发送能力和B端的接收能力的担忧而已

在网络世界中，中间节点就是路由器

重发时间：确定一个时间，如果超过时间还没收到回应，默认数据包丢失，只能重发

问题：如果发送6，7，8号数据包，其中6号数据包未到达，7号和8号数据包到达了，则也不会回送7号和8号的到达信息数据包，而是暂存起来。如果都到达了，发送了6号，7号，8号的到达信息数据包，但是其中6号丢失了，发送端收到了8号数据包，则可以直接理解为6，7号均到了，只是确认到达数据包丢失了。树立这个机制的目的是什么？

滑动窗口协议：为了提高收发效率

## CPU
为数不多的寄存器能临时记一点东西，但是运行飞快。工作以纳秒为单位。相比而言，内存慢百倍 ，硬盘慢百万倍。我的工作
* 运行指令
* 不能保存指令，指令全在内存里
* 第一条指令放在地址0xFFFFFFF0处

中断向量表

CPU运行环境
* 寄存器
* 程序计数器，记住执行的下一条指令

系统总线 I/O总线

直接内存访问（Direct Memory Access，DMA），直接把数据装载到内存，装载完成后发送一个信号

程序的局部性原理：访问了一个内存位置以后，过不了多久还会再次访问，一个内存位置被访问了，附近的位置很快也会被访问到。

流水线：4只手同时工作
* 第一只手负责打电话向内存要指令
* 第二只手翻译指令
* 第三只手执行指令
* 第四只手把结果写回内存

## 我是一个进程
冯诺依曼，提出“存储程序”的思想，各种各样不同功能的代码写好以后，和程序使用的数据一起存放在计算机的存储器中，然后计算机按照存储的程序逐条取出指令加以分析，并执行指令所规定的操作。

计算机从逻辑上分为五大部件：运算器、控制器、存储器、输入设备、输出设备

木秀于林，风必摧之

不患寡而患不均

多道程序：在内存中多装载几个程序，如果某个程序需要读/写硬盘了，你就运行另一个程序

正在运行的程序叫做进程

进程控制块：由于涉及到多道程序，那么切换程序运行的时候，就需要操作系统保存好现场，比如这个程序运行到第xxx行指令，寄存器值等，这些信息统称为进程控制块PCB

内存分配算法

在批处理系统中，所有的程序都是从地址0开始转载的。

运行时地址重定位，记录每个程序的起始地址，同时让CPU增加一个寄存器（基址寄存器），专门用来保存起始地址，每次切换程序时，由操作系统刷新寄存器的值。

> 只要是遇到与地址有关的指令，就需要把地址加上寄存器的值，这样才能得到真正的内存地址，然后去访问

那么如果有恶意程序访问别人的空间呢？CPU再增加一个新寄存器来记录程序在内存中的长度，这样每次访问的时候，那拿那个地址和这个长度比较一下，判断是否越界。

MMU（内存管理单元）：基址寄存器和长度寄存器以及计算内存地址的方法封装而成的新模块。

### 分时系统
把运行时间分成一个个小的时间片让进城使用，一个进程运行一段时间，把当前时间片用完以后，比如让出CPU，让别的进城使用。

### 分块载入
程序开始越长越大，有些图形处理程序，还有一些什么叫Java的程序，动不动就要几百MB内存，内存很快就被占满。

思考如何让有限的内存装下更多的程序呢，对于每个程序，不要全部装入内存，要分块加载，例如先把最重要的代入指令装载进来，在运行中再按需加载别的东西。

局部性原理
* 时间局部性：如果程序中某条指令开始执行，则不久之后该指令可能再次被执行，如果某数据被访问，则不久之后该数据可能再次被访问
* 空间局部性：一旦程序访问了某个存储单元，则不久之后，其附近的存储单元也将被访问

页框：定义每个小块的大小，装载程序的时候按照页框大小来进行

既然一个程序可以用分块的技术逐步跳入内存而不太影响性能，这就意味着一个程序可以比实际内存大得多。

### 虚拟内存：分页
进一步优化分块载入，给每个程序提供一个超级大空间，只不过空间是虚拟的，程序使用的是虚拟地址，然后通过MMU把他们映射到真实的物理内存地址上。

依旧采用分块装入程序，虚拟地址空间也分块，叫做页，大小和物理地址页框保持一致，这样方便映射

此时需要维护一个页表，用来映射虚拟页面和物理页面，如果程序访问了这些没被装载的页面，就从内存中找一块空闲的地方装载它（缺页处理程序）。如果内存已满，只好把现有页框中的内容换一个到硬盘上。

以后地址就分为两部分，页号和偏移量，通过MMU完成地址的转换。

同时考虑到程序运行时，都需要通过查询页表来互殴物理内存页，页表也存于内存中，但是内存只有CPU百分之一的速度。因此CPU需要增强内存管理单元，把那些最常访问的页表项放到缓存里。

### 分段 + 分页
程序分家，分成代码段、数据段、堆栈段、共享段。操作系统需要记录每个段的起始和结束地址，以及每个段的保护位（可读、可写）。

于是乎，操作系统有维护了段表这样一个东西，在每个端的内部，仍然按照分页来处理，于是地址翻译就变得复杂了。地址也分成两部分，段号和偏移量，通过段号找到段的基址，和偏移量相加，得到一个线性地址，这个线性地址再通过分页系统进行转换，最后形成物理地址。

### 线程
有了进程、分时、虚拟内存、分段和分页，是不是就足够了呢？于是就有了线程的概念。

把进程当成一个资源的容器，在里面运行几个轻量级的进程，就叫做线程吧。这些线程共享进程的所有资源，如地址空间、全局变量、文件源等。但每个线程也有自己独特的部分，就要要记住自己运行到哪些指令，有自己的函数调用栈，自己的态等。

## 我是一块硬盘
CPU和内存是计算机的核心，所有的运算都得通过他们来完成，CPU从内存中读取指令，进行计算，然后写回内存，如此周而复始。

如果能够制造出一块能够断电存储、大容量、访问速度快，当然还便宜的硬盘，CPU就能直接访问硬盘了，内存就一边凉快去吧。但在制造出来之前，你必须容忍CPU、内存、硬盘之间速度的不匹配，并且想办法解决这种速度不匹配，比如使用缓存、直接内存访问、多进程/线程切换等

内部结构
* 很多盘片组成
* 每个盘片都有一圈一圈的磁道，每个磁道分为一个一个的扇区
* 多个盘片上的同一位置的磁道组成了一个柱面
* 每个盘片都有可以读写的磁头
* 寻道时间：磁头挪到你指定的柱面
* 旋转时间：磁头指向你指定的扇区，因此转速快的硬盘能更快的转到指定扇区，所以性能会更好一些

### 文件
LBA（Logical Block Addressing）寻址方式，磁盘由一个一个块组成，磁盘内部把对应块转换成柱面、磁头、扇区。

文件和目录：使用户不需要和烦人的磁盘块打交道，只需要记住你的文件名和路径，其余的事情交给磁盘和操作系统即可

> 文件对人类而言是最小的存储单位

文件的存放：如何记录各个文件用到了哪些磁盘块
* 连续分配：这种放随机访问时效率极好，因为你只要知道了开头和长度，就想数组一样可以随便访问。缺点：如果之前的文件被删除了，留下了空洞，如果之后没有大小合适的文件过来，就永远空着了，造成了浪费
* 链式分配：随机访问效果太差，每次都得从第一块磁盘开始，沿着链条往后找。
* 索引式：专门找个磁盘块，里面存放着文件所使用的磁盘块号列表。通过它可以轻松找到文件所使用的所有磁盘块，无论顺序访问还是随机访问，速度都很快。唯一的缺点就是索引块本身也要占空间，如果文件很小，只要占用一个磁盘块，也必须分配完整的索引块。

> inode结构，不仅记录的此判断，还记录了文件的权限、所有者、时间标记

### 管理空闲块
负责将没有使用的、空白的磁盘块管理起来，当新的文件到来的时候，才能分配存储空间
* 链式大法：空闲磁盘块组成链表，缺点：由于每个块都需要记录下一个块号，浪费空间
* 位图法：对于每个磁盘块。如果已经使用，就标记为1，没被使用就标记为0，每个磁盘块只用一个bit表示，非常节省空间，很赞

### 文件系统
如何高效的实现包含文件和目录的树形结构。文件系统有很多种类，比如NTFS、FAT、Ext2、Ext3等

## 我是一个键盘
二等公民：输入/输出（I/O）设备

二等公民的分类：块设备和字符设备
* 硬盘、CD-ROM、U盘是典型的块设备，数据都存储在固定的大小块中，每个块都有一个地址
* 键盘、鼠标、打印机就是字符设备，一个个字符组成的流而已，也没什么地址

还有一种分法是存储设备（硬盘）、传输设备（网卡、调制解调器）、人机交互设备（键盘、鼠标、显示器）

### 总线与端口
CPU如何和我们打交道呢？一种办法是在CPU和每个I/O设备之间扯一根线，有多少设备就扯多少根线，组成一个以CPU为中心的星线布局，缺点：麻烦，不利于扩展。

因此我们采用了总线这个概念，大家都挂载到这个总线上，CPU通过总线进行通信，这种方式的缺点时，当有人在占用总线时，其他人就得等待。设备过多，CPU怎么知道是谁呢？因此需要给每个设备编号，这些编号称为I/O端口

内存映射I/O：CPU将I/O端口映射到内存中去，这样CPU访问我们的时候，就像访问内存地址一样

轮询（程序式I/O）：CPU运算太快，而I/O设备运算太慢，如果采用轮询的方式，CPU会一直占用总线，不断问道是否完成了。这显然是不合理的

中断：中断请求线，I/O设备完成后往这里发送信号即可，CPU每执行完一条指令都会去检查。

中断控制器：专门负责协调，只有它才能给CPU发中断，负责裁决谁的优先级高

> 这种中断的方式其实就是异步的、事件驱动的思想，在计算机软硬件上使用非常广泛，如Node.js，AJAX

DMA控制器：使用这个专用的处理器进行I/O设备和内存之间的直接数据传输