## 编译执行
高级语言可以被粗略的分为三类：编译型语言、解释型语言、混合型语言，其中，Java属于混合型语言。混合型语言也叫做半解释型语言，它融合了编译型语言和解释型语言的特点，既兼顾了可移植性，又兼顾了执行效率。Java的编译执行过程包括前端编译、类加载、解释执行、JIT编译执行、AOT编译这5部分内容。
* 前端编译：指的是将 .java 文件编译城 .class 字节码的过程，由 javac 编译器来完成。实际上，前端编译过程跟编译型语言中的编译过程类似，它们都需要经过词法分析、语法分析、语义分析等经典的编译过程。两者的区别在于，Java前端编译的结果为字节码，编译型语言中的编译结果为机器码。
* 类加载：在Java应用程序执行的过程中，类的字节码是按需加载到内存中的。当类第一次创建对象，或者类的方法被调用时，这个类就会被加载到内存中。类加载的过程又可以细分为验证、准备、解析、初始化等几个步骤，并且，类的加载遵从双亲委派规则，不同的类由不同的classLoader加载器来加载。
* 解释执行：对于C/C++这样的编译型语言，代码会事先被编译成机器指令（即可执行文件），直接交由CPU逐条执行即可。而对于Java语言来说，经过前端编译之后的.class文件，被加载到内存之后，仍然为字节码格式，无法被CPU直接执行。JVM虚拟机需要将字节码逐条取出，边解释为机器指令边交由CPU执行。
* JIT编译执行：解释执行需要在执行的过程中，将字节码解释为机器码，再行交由CPU执行。边解释边执行显然会影响到程序的执行效率，这也是在Java语言发明之初，被认为执行效率没有编译型语言（比如C/C++）高的原因。随着Java语言的发展，为了解决解释执行效率低的问题，Java引入了JIT（Just-in-Time）编译（也叫做即时编译或者运行时编译）。对于频繁执行的热点代码，比如多次调用的方法或者反复执行多次的循环，JIT编译器在代码的运行过程中，将其编译为机器指令并存储下来。当下次执行这些热点代码时，虚拟机直接将对应的机器指令交由CPU执行即可，不需要边解释边执行，执行效率匹敌编译型语言。
* AOT编译：实际上，跟JIT编译相对应的编译方法称作AOT编译（Ahead Of Time Compile），也叫做提前编译或者运行前编译。C/C++等编译型语言中的编译便是AOT编译，即在运行前将代码编译成机器码。实际上，除了支持JIT编译之外，Java也支持AOT编译，只是相对不常见而已。

不过，Java AOT编译跟C/C++等编译型语言中的编译有些许不同。对于C/C++等编译型语言，代码的可移植性完全由程序员来负责，很难做到“一次编写，到处运行”。尽管Java AOT编译不支持“一次编译，到处运行”，但仍然支持“一次编写，到处运行”，代码的可移植性完全由AOT编译器来负责。针对不同的操作系统，我们使用不同的AOT编译器，生成不同的机器指令。既然AOT编译既可以在运行前将代码编译成机器指令，同时又可以做到“一次编写，到处运行”，那么，Java为什么还偏向于使用JIT编译呢？

一般来说，编译包含两部分工作，一部分工作是基础编译，即将代码编译成字节码、机器指令等，另一部分工作是编译优化。AOT编译中进行的编译优化为静态编译优化，JIT编译中进行的编译优化为动态编译优化。相比静态编译优化，动态编译优化有很多优势，它可以基于运行时的统计信息，进行一些比较激进的优化，比如根据运行时的统计信息，直接移除执行概率比较小的代码分支。在实际的运行中，如果万一需要执行被移除的代码分支，那么，虚拟机会退回到使用原始的字节码来解释执行。只要退回到解释执行的概率足够低，这种激进优化就是值得的，带来的性能提升就是非常可观的。这就是Java偏向于使用JIT编译而非AOT编译的原因。

除此之外，JVM不仅仅支持Java编程语言，只要是能够编译成字节码的编程语言，比如Clojure、Groovy、JRuby、Scala，都可以运行在JVM之上。也就是说，JVM并不关心字节码来自于哪种编程语言，只要字节码符合JVM规范即可被JVM执行。这也是Java一直偏向于使用JIT编译的原因。

## JIT 编译器
HotSpot虚拟机支持两种JIT编译器：Client编译器和Server编译器。其中，Client编译器又叫做C1编译器，Server编译器又叫做C2编译器。两种编译器的区别在于编译时间和编译优化程度有所不同，并且编译时间跟编译优化程度成正比。编译优化程度越高，最终生成的机器码就越高效，当然，也要付出更多的编译时间作为代价。Client编译器只进行局部的编译优化，是一种编译时间短、编译优化程度低的编译器，Server编译器进行局部和全局的编译优化，是一种编译时间长、编译优化程度高的编译器。

我们常说JVM有两种运行模式：Client模式和Server模式，实际上，这两种运行模式就是基于JIT编译器的类型来区分的。在Java7及其以前版本中，我们可以通过-client或-server这两个VM参数来指定JIT编译器的类型。对于长时间运行的程序，我们可以牺牲一些编译时间，生成一些更加高效的机器码。因此，服务器一般选择Server编译器，即Server工作模式。相反，客户端一般选择Client编译器，即Client工作模式。

在Java7之前，虚拟机要么选择Client编译器，要么选择Server编译器，两种编译器无法同时使用。为了解决这个问题，Java7引入了分层编译的技术，对编译类型做了更加细化的区分，使虚拟机能够根据不同代码、不同时刻的实际运行情况，选择不同的编译类型，编译工作更加精细化和有针对性。

分层编译技术在Java7中并不是特别成熟，因此，JVM默认是不开启的。我们需要使用-XX:+TieredCompilation参数来开启分层编译。随着技术发展，分层编译技术在Java8中变得稳定成熟，因此，JVM默认开启分层编译技术，并且，无论开启还是关闭分层编译，-client和-server参数都不再有效。当分层编译技术被关闭时，JVM直接选择使用Server编译器。

前面提到，只有当代码被判定为热点代码时，JVM才会触发JIT编译。那么，具体什么样的代码才是热点代码呢？实际上，热点代码主要有这样两类：第一类是被多次执行的方法，第二类是被多次执行的循环。需要注意的是，JIT编译的对象是方法。对于第二类热点代码，JIT编译的对象是包含这个循环的方法，而非只是循环本身。

HotSpot虚拟机使用计数器来统计方法或循环的执行次数，以此来判断方法或循环是否是热点代码。JVM对每个方法维护两个计数器：方法调用计数器和回边计数器。方法调用计数器用来统计方法的执行次数。回边计数器用来统计方法内循环的执行次数。

当某个方法的方法调用计数器的值和回边计数器的值的总和超过某个阈值时，虚拟机就会对这个方法进行JIT编译。对于Client编译器，这个阈值默认为1500。对于Server编译器，这个阈值默认为10000。当然，我们也可以通过参数-XX:CompileThreshold人为指定阈值。不过，如果虚拟机开启了分层编译，那么虚拟机不再使用以上固定的阈值，转而使用动态阈值。动态阈值根据当前编译方法数以及编译线程数动态计算得到。

从上述描述，我们可以发现，随着运行时间的增长，某个方法只要一直在执行，就总是会出现其调用次数高于阈值的情况。这就会导致一些不怎么频繁运行的代码也会被判定为热点代码。为了解决这个问题，虚拟机引入了热度衰减机制。在超过一定的时间之后（这个时间通过参数-XX:CounterHalfLifeTime来设置），如果某个方法没有达到触发JIT编译的阈值要求，那么这个方法的方法计数器的值就减半。

不管是前端编译、JIT编译，还是AOT编译，编译器要做的工作除了基本的编译之外，还有另外一项非常关键的工作，那就是编译优化。所谓编译优化指的是，编译器在编译代码时，对代码进行优化，减少无效、冗余代码，以便生成更加高效的机器码。在一定程度上，编译优化的质量决定了编译器是否优秀、编程语言是否高效。

JIT编译的编译优化策略有很多，比如经典的函数内联、逃逸分析、无用代码消除、循环展开、消除公共子表达式、范围检查消除、空值检查消除等等。 对于这些编译优化策略，我们没有必要去深入研究，毕竟编译优化对于大部分程序员来说都是黑盒子。不过，为了让你对编译优化策略有一些直观的认识，我们拿其中的函数内联和逃逸分析作为示例来讲解。

函数内联：函数调用会涉及到栈帧的压栈、出栈，以及现场的保存和恢复，因此，相对于普通的代码执行，函数调用要慢很多。为了减少函数调用以提高代码执行效率，对于一些比较短小的函数，比如getter、setter函数，虚拟机在编译代码时，直接将这类函数的代码嵌入到函数调用处。示例如下所示。当然，这会导致同一份函数代码被复制到各个地方，内存消耗增多，因此，这是一种空间换时间的优化手段。

逃逸分析：JIT编译器通过分析对象的使用范围来优化对象的存储方式和访问方式，以提高代码的执行效率。针对不同的逃逸分析结果，编译器有3种不同的优化策略，它们分别是：栈上分配、标量替换、锁消除。

## 类加载
类加载主要包括类加载过程和类加载机制这两部分内容。其中类加载过程包括验证、准备、解析、初始化，类加载机制包括类加载器和双亲委派机制。

类加载指的是虚拟机将类的二进制字节码加载到内存中，以便创建类的对象或者执行类上的方法。类加载的过程可以细分为：验证、准备、解析、初始化这4个阶段。
* 验证：虚拟机加载类字节码时，做合法性校验
* 准备：在准备阶段，虚拟机为类的静态变量分配内存，并将其初始化为默认值，比如，对于private static int a = 25这一语句，虚拟机会在准备阶段将变量a初始化为int类型的默认值0，而指定值25会在初始化阶段再赋值给变量a。需要注意的是，对于static final修饰的静态常量，虚拟机直接在准备阶段将其初始化为指定值，比如，对于private static final int a = 25这一语句，虚拟机在准备阶段将变量a初始化为25。
* 解析：解析类似C++中的链接，把类字节码的常量池中的符号引用（也被称为间接引用）转换为直接引用。前面讲到，常量池中存储了所涉及的类、方法、变量等的名称和编号，这一步就是将代码中的编号转化为可以直接访问的内存地址（也就是刚刚提到的直接引用）。
* 初始化：在初始化阶段，虚拟机会执行静态变量的初始化代码，包括初始化语句（比如private static int a = 25；）和静态代码块（比如static { a = 13; }）。

类加载由类加载器来完成。虚拟机定义了几种不同类型的类加载器：启动类加载器（Bootstrap ClassLoader）、扩展类加载器（Extension ClassLoader）、应用程序类加载器（Application ClassLoader）。其中，启动类加载器负责加载$JAVA_HOME/jre/lib/rt.jar包中的类，扩展类加载器负责加载$JAVA_HOME/jre/lib/ext目录下的jar包中的类。应用程序类加载器也叫做系统类加载器，负责加载classpath中除启动类加载器和扩展类加载器所负责的路径之外的其他路径下的类。

尽管每个加载器所负责的路径是明确的，但是，虚拟机无法根据类的全限定名（包含package信息的类名，比如java.lang.StringUtils）获知类处于哪个路径下，也就无法获知这个类归属于哪个类加载器负责。除此之外，不同的路径下可能存在名称相同的类，比如在$JAVA_HOME/jre/lib/下和./下都有可能存在java.lang.StringUtils这个类，对于这种情况，虚拟机还需要有一定的机制来确定到底应该加载其中哪个类。

以上描述可以总结为两个问题：类的查找和去重问题。为了解决这两个问题，虚拟机设计了双亲委派机制。在双亲委派机制中，虚拟机首先定义了类加载器之间的父子关系。

一般来说，虚拟机需要加载某个类时会先请求应用程序类加载器来加载。当然，我们也可以通过编程改为请求其他类加载器加载类，比如请求自定义类加载器加载某个类。在类加载器接收到某个类的加载请求后，如果这个类加载器之前没有加载过这个类，那么，它便委托父类加载器加载这个类，如果父类加载器之前也没有加载过这个类，那么，父类加载器又会委托父类的父类加载器加载这个类，以此类推，一直往上委托。如果在往上委托的过程中，某个类加载器已经加载了这个类，那么类加载过程结束。如果没有任何类加载器加载过这个类，那么，虚拟机会再从上往下依次请求各个类加载器加载这个类，直到某个类加载器成功加载这个类为止（即这个加载器所负责的类路径中存在这个类）。如果没有任何类加载器可以成功加载这个类，那么，虚拟机抛出ClassNotFoundException异常。

以上基于双亲委派的类加载机制可以有效的防止核心类被恶意替换。假设我们在项目路径下定义一个新的java.lang.String类，意图覆盖核心类库中的java.lang.String类，但是，基于双亲委派机制，应用程序类加载器会委托父类加载器来加载java.lang.String类，因此，最终虚拟机加载的java.lang.String类仍然是由启动类加载器加载的核心类库中的java.lang.String类。

## 内存分区
编译执行的结果会存放在内存中，这其中就包括代码和数据。为了区别对待所存储的不同内容，JVM将内存划分为不同的分区，其中包括方法区、程序计数器、堆、虚拟机栈、本地方法栈。

方法区
* 类信息：类的全限定名、访问标志以及父类、接口列表等相关信息。
* 方法信息：方法的字节码、局部变量表、异常表、参数信息等；
* 静态变量：静态变量隶属于类，因此存储在方法区中而非堆上。
* 运行时常量池：存储字面量和符号引用。每一个类会对应一个运行时常量池。
* 字符串常量池：此分区专门服务于字符串，避免String对象的重复创建，减少内存开销。跟运行时常量池不同，字符串常量池是类之间共享的。
* JIT编译代码缓存：此分区存储的是JIT编译之后的机器码。

CPU在执行指令的过程中使用程序计数寄存器（Program Counter Register，简称为PC寄存器）存储下一条将要执行的指令的地址。实际上，虚拟机就相当于一个抽象的计算机，也有自己的指令集，那就是字节码集。虚拟机在对字节码进行解释执行的过程中，也需要有这样一个存储单元，存储下一条将要执行的字节码的地址。虚拟机将这个存储单元称为程序计数器。

程序计数器跟PC寄存器的不同之处在于，PC寄存器是线程共享的，PC寄存器的值会随着线程的切换而进行保存和恢复。而程序计数器是线程私有的，虚拟机为每个线程分配一个独立的程序计数器，记录每个线程执行到哪一行字节码。之所以有这样的区别，是因为PC寄存器的价格比较昂贵，数量有限，而程序计数器位于内存中，价格没那么昂贵。线程独享程序寄存器能减少线程上下文切换的信息量，有利于提高线程切换的速度。

堆用来存储Java对象。在Java中，对象的回收是由虚拟机中的垃圾回收器自动完成的。堆是垃圾回收器的主要工作分区。为了配合垃圾回收算法，堆又被划分为更加细粒度的分区，比如堆被划分为年轻代（Young Generation）和老年代（Old Generation），年轻代又被划分为Eden区和Survivor区，而Survivor区又被划分为From Survivor区和To Survivor区。对于堆，我们会在后面的章节中，结合分代垃圾回收算法进行更加详细的讲解。

在第2节中，我们详细讲解了函数调用的实现原理，其中所涉及到的重要的内存结构便是栈。栈用来存储函数调用的局部变量、参数、返回地址等信息，因此，栈也被叫做函数调用栈。栈为线程私有的，每个线程都会有一个栈，因此，栈也被叫做线程栈。Java也不例外，我们把Java中的栈叫做虚拟机栈。

Java提供了很多采用C/C++语言实现的native方法。很多Java函数最终是通过调用native方法来实现的。在JVM规范中，Java将服务于Java方法调用的栈跟服务于native方法调用的栈做了区分。服务于Java方法调用的栈被称为虚拟机栈，而服务于native方法调用的栈被称为本地方法栈。实际上，这两个栈的功能基本是相同的，在具体的虚拟机实现中，这两栈有可能会被合并为一个栈，同时存储Java方法调用的栈帧和native方法调用的栈帧。实际上，HotSpot JVM就是这么做的。

在不同平台下，JVM的默认线程栈大小有些许差别。在64位Linux操作系统下，HotSpot JVM的默认线程栈大小为1MB，当然，我们可以通过JVM参数-Xss来自定义线程栈的大小。JVM可创建的线程个数由进程可用内存大小（一般就是计算机可用内存）除以线程栈大小决定。我们可以通过减小线程栈大小来支持创建更多的线程。当然，我们也可以通过增大线程栈大小来避免函数调用过深导致的栈溢出（即栈内存不够用导致JVM抛出StackOverflowError异常）。

## 可达性分析
虚拟机在进行垃圾回收时，首先需要判断哪些对象可以被回收。常用的判断方法有**引用计数和可达性分析**，不过，前者并不常用，我们只对其做简单介绍。本节我们重点介绍可达性分析以及其中涉及到的STW、安全点、安全区等知识点。

在Java中，我们使用引用来表示变量和对象之间的关系，将对象赋值给变量就表示变量引用对象。如果N个变量同时引用某个对象，那么，这个对象的引用计数就是N。如果引用这个对象的某个变量取消与这个对象之间的引用关系，比如变量改为引用其他对象、或者被赋值为null、又或者其生命周期结束，那么，这个对象的引用计数便会减一。当这个对象的引用计数减少为0时，这个对象就可以被虚拟机当做垃圾回收了。

不过，引用计数存在一个严重问题，那就是无法检测循环依赖。如下所示，两个对象互相引用，尽管最后不再有变量引用它们，但它们引用计数仍然不为0，也就无法被回收。这就是大部分虚拟机不使用引用计数作为判定对象是否应该被回收的原因。
```java
Wife hanmeimei = new Wife("HanMeiMei"); //Wife对象的引用计数为1
Husband lilei = new Hasband("LiLei"); //Husband对象的引用计数为1
hanmeimei.husband = lilei; //Husband对象的引用计数为2
lilei.wife = hanmeimei; //Wife对象的引用计数为2
hanmeimei = null; //Wife对象的引用计数为1
lilei = null; //Husband对象的引用计数为1
```

在可达性分析中，我们使用数据结构中的**有向图来表示对象之间的引用关系**。有向图中的顶点表示对象。如果对象A中的变量引用了对象B，那么，我们便在对象A对应的顶点和对象B对应的顶点之间画一条有向边。

有向图中包含一组特殊的顶点，叫做GC Roots。GC Roots为堆外变量所直接引用的堆内对象，包括虚拟机栈和本地方法栈中的局部变量所直接引用的对象以及方法区中静态变量所直接引用的对象等。虚拟机以GC Roots为起点，通过深度优先或广度优先算法来遍历整个有向图。遍历到的对象为可达对象，也叫做存活对象，遍历不到的对象为不可达对象，也叫做死亡对象。死亡对象会被虚拟机当做垃圾回收。

我们把运行在虚拟机上的应用程序所启动的线程叫做用户线程，我们把执行垃圾回收的线程叫做垃圾回收线程。如果虚拟机在执行垃圾回收的同时，用户线程仍然在执行，那么，对象之间的引用关系有可能被用户线程中途更改，这就会导致可达性分析存在误报或者漏报的情况。

误报指的虚拟机将死亡对象误报为存活对象，漏报指的是虚拟机将存活对象漏报，漏报的存活对象会被判定为死亡对象。关于误报和漏报产生的详细原因，我们在后面讲到三色标记算法时再详细讲解。误报并不会产生问题，它只会导致本该被垃圾回收的对象没有被回收，等待再次垃圾回收即可。漏报会产生严重的问题，它会导致本不该被回收的对象被回收，这显然是无法接受的。

为了解决漏报的问题，比较简单粗暴的解决方法是虚拟机在进行垃圾回收时停止所有用户线程，这样垃圾回收过程就不会被用户线程所打扰。我们把这个过程形象化地称为Stop The World，简称为STW。STW的时间过长会严重影响应用程序的性能，特别是对响应时间比较敏感的应用程序来说，这种影响尤为明显。因此，尽量减少STW的时间是每个垃圾回收器努力的重点。关于如何减少STW的时间，我们在后续讲解CMS、G1等垃圾回收器时再详细讲解。

前面提到，可达性分析遍历的起点是GC Roots，那么，GC Roots又是如何获得的呢？比较简单的方法是，虚拟机遍历栈中的局部变量和方法区中的静态变量，然后从中找出引用类型变量，最后再将引用类型变量所引用的对象放入GC Roots中。

每当进行垃圾回收时，虚拟机都要遍历栈和方法区来查找GC Roots，这样做效率非常低。因此，虚拟机使用OopMap来存储当前的GC Roots并实时动态更新。具体的做法是：虚拟机先遍历查找一次GC Roots并初始化OopMap，然后，在代码的执行过程中，如果有变量更新所引用的对象，那么，虚拟机就同步更新OopMap。当虚拟机需要进行垃圾回收时，OopMap中存储的便是当前的GC Roots。

对于解释执行来说，上述OopMap的更新过程没有任何问题。虚拟机每执行一行字节码就同步更新一下OopMap。但是，对于JIT编译执行来说，上述OopMap的更新过程却无法实现。这是因为JIT编译之后的机器码直接交由CPU执行，并不经虚拟机之手。虚拟机无法做到边执行指令边分析指令然后再动态更新OopMap。为了解决这个问题，虚拟机需要在将字节码编译为机器码时，静态地分析指令，然后为每一条指令存储此指令执行结束后对应的OopMap，但是，这样做显然非常浪费内存空间。

为了解决内存的浪费问题，虚拟机采用时间换空间的策略，将为每个指令存储一个OopMap改为只为部分指令存储OopMap。这些被选取的部分指令被称为安全点。当虚拟机启动垃圾回收并发起STW请求时，会向用户线程发送暂停的中断请求。用户线程接收到中断请求之后并不能立刻停止运行，而是需要继续运行到安全点之后才能停止运行，这是因为只有安全点处才记录了OopMap，只有所有的线程都运行到安全点之后，虚拟机才能得到完整的GC Roots。

在大部分情况下，用户线程在接收到暂停的中断请求之后，都可以在较短的时间内到达最近的安全点，但是，在少数情况下，如果用户线程处于阻塞状态（比如等待I/O读写就绪），那么，就无法在较短的时间内到达最近的安全点。为了解决这个问题，虚拟机引入了一个新的概念：安全区。安全区指的是不会改变对象引用关系的一段连续的代码区间，比如线程阻塞等待I/O读写就绪期间并不会改变对象的引用关系，因此，对应代码就属于安全区。

当虚拟机执行垃圾回收并发起STW请求时，如果某个线程处于安全区，那么，这个线程并不需要停止执行，而是可以跟垃圾回收线程并行执行。但是，当用户线程离开安全区时，它需要检查虚拟机是否处于STW状态，如果虚拟机处于是STW状态，那么，用户线程需要阻塞等待STW结束，才能继续往下执行，以免用户线程跳出安全区之后，执行非安全代码导致对象引用关系的改变。

## 垃圾回收算法
垃圾回收算法又分为基础垃圾回收算法和分代垃圾回收算法。分代垃圾回收算法在基础垃圾回收算法之上增加了分代的概念。虚拟机将堆空间分为年轻代和老年代。针对不同的分代单独进行垃圾回收。针对年轻代的垃圾回收叫做YoungGC，针对年轻代、老年代、永久代的垃圾回收叫做FullGC，FullGC要比YoungGC慢很多。那么，请你思考，同为垃圾回收，为什么FullGC要比YoungGC慢很多呢？

基础垃圾回收算法有三种，它们分别是：标记-清除、标记-整理、标记-复制。从名称上，我们也可以看出，无论哪种算法，第一步总是先标记，也就是使用可达性分析找出需要被回收的死亡对象。它们的不同点在于第二步（清除、整理或复制）。

标记-清除算法存在内存碎片问题，即经过标记-清除之后得到的空闲空间不连续。这就会导致内存分配效率和内存利用率不高。为对象查找大小合适的空闲空间比较耗时，并且内存碎片有可能因为过小和过凌乱而无法被大对象使用。相对于其他基础垃圾回收算法，标记-清除算法的优点是逻辑简单，垃圾回收速度快。后面讲到的CMS垃圾回收器就用到了标记-清除算法，并在此基础上做了改进，即多次垃圾回收之后进行一次碎片整理。

标记-整理算法也叫做标记-压缩算法，在标记-清除算法的基础之上，标记-整理算法额外增加了“整理”的环节。标记-整理算法先通过可达性分析标记存活对象，然后，顺序遍历内存空间，将存活对象移动到内存的一端，从而解决了内存碎片问题。

标记-复制算法将整个内存分为两块。其中一块内存为对象分配内存空间，称为工作内存，另外一块内存作为复制时备用，称为备用内存。当工作内存使用完之后，标记-复制算法将这块内存中的存活对象，逐一复制到备用内存中，然后，两块内存互换角色。

尽管标记-复制算法没有内存碎片的问题、垃圾回收速度快，但存在内存利用率不高的问题，只有50%，并且，如果对象的存活时间比较长，那么，对象会在两块内存之间来回复制多次，比较浪费时间。

在讲解JVM内存模型时，我们讲到，根据功能的不同，JVM将所使用的内存划分为不同的分区，它们分别是：方法区、程序计数器、堆、虚拟机栈、本地方法栈。其中，程序计数器使用的内存非常少，并且随着线程的创建而创建，随着线程的销毁而销毁。虚拟机栈和本地方法栈存储的是方法对应的栈帧。栈帧随着方法的调用而入栈，随着方法的退出而出栈。因此，程序计数器、虚拟机栈、本地方法栈这三个分区中的垃圾数据会随着生命周期的结束而被立刻回收，不需要经过虚拟机的垃圾回收线程的处理。

堆中存储的是对象。对象供所有线程共享，其作用域范围大，生命周期长。在使用完成之后，对象并不会被立刻回收。因此，堆是虚拟机进行垃圾回收的重点工作分区。不过，除了堆之外，方法区也会涉及垃圾回收，比如，方法区中的一些无用的类或者无用的String常量对象也需要被回收。无用的String常量对象指的是，存储在字符串常量池中的并且没有变量引用的String对象。无用的类指的是要同时满足以下几个条件的类。
* 该类的所有对象都已经被回收；
* 类的Class对象（比如Class<?> clazz = Integer.class;）没有任何变量在引用；
* 加载该类的类加载器已经被卸载。

应用程序所创建的对象的生命周期并不相同，有的对象的生命周期比较短，比如方法内的对象，有的对象的生命周期比较长，比如使用Spring框架创建的单例对象。对于生命周期较短的对象，我们希望以较高的频率执行垃圾回收，尽快释放所占用的内存空间。对于生命周期较长的对象，我们希望以较低的频率执行垃圾回收，避免无效的垃圾回收。

因此，虚拟机将堆分为年轻代（Young Generation）和老年代（Old Generation）。年轻代存储生命周期比较短的对象，老年代存储生命周期比较长的对象。虚拟机针对不同的分代（年轻代和老年代），使用不同的基础垃圾回收算法（标记-清除、标记-整理、标记-复制）。在基础垃圾回收算法之上增加分代之后的垃圾回收算法，叫做分代垃圾回收算法。

### 年轻代和 YoungGC
新创建的对象会分配在年轻代，因此，年轻代也叫新生代（New Generation）。根据统计数据发现，在应用程序中，大部分对象都朝生夕死，存活率比较低，因此，年轻代适合使用标记-复制算法进行垃圾回收。在进行垃圾回收时，虚拟机只需要复制少量存活对象，复制耗时少，执行效率高。我们把年轻代的垃圾回收叫做YoungGC。

前面提到，标记-复制算法会将整个内存平均分为两块，同一时间只有一块内存在使用，内存利用率只有50%。为了提高内存利用率，虚拟机对标记-复制算法进行了优化，将年轻代分为不均等的三个分区：一个Eden区和两个大小相等的Survivor区。

虚拟机将Eden区和其中一个Survivor区作为分配对象所用，也就是工作分区，将另一个Survivor区作为复制备用，也就是备用分区。除此之外，我们把供分配对象所用的Survivor区叫做From Survivor区，将复制备用的Survivor区叫做To Survivor区。当工作分区（Eden区和From Survivor区）存满之后，虚拟机便执行标记-复制算法，将Eden区和From Survivor区中的存活对象复制到To Survivor区。当一次垃圾回收结束之后，两个Survivor区的角色互换，原来充当From Survivor的，现在充当To Survivor，原来充当To Survivor的，现在充当From Survivor。

一般情况下，Eden区比较大，Survivor区比较小。默认情况下，虚拟机根据每次垃圾回收之后存活对象的比例，动态调整Eden区和Survivor区的大小比例，当然，我们也可以通过JVM参数-XX:SurvivorRatio设置固定的比例，比如，-XX:SurvivorRatio=8表示Eden区和一个Survivor区的大小比例为8:1，也就是说，Eden区占年轻代大小的80%，From Survivor和To Survivor各占10%。工作内存为Eden区加From Survivor，因此，内存利用率高达90%。尽管To Survivor区比较小，但基于前面讲到的“大部分对象都朝生夕死”这一规律，在大部分情况下，To Survivor区的大小都足够存一次垃圾回收之后的存活对象。

如果万一To Survivor区存不下一次垃圾回收之后的存活对象，那么，该怎么办呢？对于这种情况，虚拟机会借用老年代的部分空间，将存不下的对象存储在老年代中。在这里，老年代相当于起到了一个担保的作用，因此，这种处理机制叫做空间分配担保。当然，这也会导致一定的问题：部分生命周期比较短的对象存储到了老年代，即便这些对象早早已经死亡，依然需要等待很长时间才能被回收。

如果老年代也没有足够的空间用于分配担保，那么，又该怎么办呢？对于这种情况，虚拟机会执行FullGC（待会会讲到），对整个堆进行一次大规模的垃圾回收，以便腾出更多空闲空间。如果虚拟机在执行完FullGC之后，老年代仍然没有足够的空间，那么，虚拟机就只能抛出OOM（Out Of Memory，即内存溢出）异常了。

### 老年代和 FullGC
刚刚讲到，基于空间分配担保机制，新生代存不下的对象会进入老年代，除此之外，大对象和长期存活对象也会进入老年代。

大对象指的是占用大量连续内存空间的对象，比如大的字符串或数组。默认情况下，不管对象有多大，都会在年轻代创建，但是，如果我们设置了JVM参数-XX:PretenureSizeThreshold，那么，当对象的大小超过这个预设的阈值之后，对象会直接在老年代创建。这样做的目的是避免生命周期比较长的大对象在年轻代中被反复复制。

长期存活的对象指的是经过多次年轻代的垃圾回收后仍然存活的对象。虚拟机在对象的对象头中记录对象的GC年龄，每经过一次GC，GC年龄就增一，当GC年龄超过一定阈值（默认为15，当然，我们也可以通过-XX:MaxTenuringThreshold来设置这个阈值）之后，对象便会从年轻代移动到老年代。不过，人为设定一个固定值显然不够灵活，于是，虚拟机设计了动态年龄判定机制，结合存活对象的多少来动态地设置最大GC年龄。

动态年龄判定机制的具体的做法是：统计YoungGC后，处于每个GC年龄值的对象占To Survivor区的比例。按照年龄从小到大累加对象所占比例，当累加到年龄为X的对象时，如果累计对象所占比例超过50%（此值可以通过JVM参数-XX:TargetSurvivorRatio来设置），那么，GC年龄>=X的对象都将直接进入老年代，并不会等到GC年龄大于15。

我们举个例子解释一下。假设根据统计我们发现，GC年龄=3的对象占To Survivor区大小的20%，GC年龄=6的对象占To Survivor区大小的40%，GC年龄=8的对象占To Survivor区大小的15%。在这个例子中，GC年龄=3的对象和GC年龄=6的对象占To Survivor区的比例为60%，超过50%，因此，GC年龄=6和GC年龄=8的对象会从年轻代移动到老年代。

前面讲到，年轻代使用标记-复制算法进行垃圾回收，原因是年轻代中的存活对象比较少，复制耗时少。而老年代正好相反，老年代中的对象的生命周期比较长，存活对象比较多，复制耗时多，因此，老年代一般采用标记-整理算法或标记-清除算法进行垃圾回收。

前面讲到，我们把年轻代的垃圾回收叫做YoungGC，相对应的，我们把老年代的垃圾回收就叫做OldGC，但是，在主流虚拟机的实现中，比如HotSpot JVM，在对老年代进行垃圾回收的同时，虚拟机会一并对年轻代和永久代（或元空间）进行垃圾回收。我们把这种大规模的垃圾回收叫做FullGC。接下来，我们来看下本节开头的问题：同为垃圾回收，为什么FullGC要比YoungGC慢很多？

有了以上知识的铺垫，这个问题就比较简单了。YoungGC只针对年轻代进行垃圾回收，年轻代中的对象的存活率比较低，可达性分析需要遍历的对象和需要进行复制的对象比较少，所以，YoungGC比较快速，因此，YoungGC也被称为MinorGC。而FullGC针对年轻代、老年代、永久代（或元空间）进行垃圾回收，并且老年代和永久代（或元空间）中的对象存活率比较高，可达性分析需要遍历的对象和垃圾回收需要处理的对象比较多，所以，FullGC比较慢，因此，FullGC也被称为MajorGC。

## 垃圾回收器
垃圾回收器性能指标
* 吞吐量：吞吐量指的是应用程序运行时间占总运行时间的比值。总运行时间等于应用程序运行时间加上垃圾回收时间（简称GC时间）。吞吐量95%表示在总运行时间中，应用程序运行时间占比95%，GC时间占比5%。吞吐量越大，表示浪费在GC上的时间越少。
* 停顿时间：停顿时间指的是垃圾回收导致应用程序完全停止运行的时间，也就是STW时间。
* 资源消耗：资源消耗指的是虚拟机进行垃圾回收所消耗的CPU和内存资源。

为了满足不同的应用场景，虚拟机提供了很多不同的垃圾回收器，我们按照实现方式（串行还是并行、是否Stop-The-World、针对年轻代还是老年代等）将众多垃圾回收器分为4类：Serial垃圾回收器、Parallel垃圾回收器、CMS垃圾回收器、G1垃圾回收器。

Serial垃圾回收器使用单线程进行垃圾回收，并且，在进行垃圾回收时，虚拟机需要暂停应用程序的运行（也就是Stop The World）。Serial垃圾回收器又分为Serial New和Serial Old。Serial New用于年轻代的垃圾回收，基于标记-复制算法来实现。Serial Old用于老年代的垃圾回收，基于标记-整理算法来实现。

Parallel垃圾回收器使用多线程进行垃圾回收，可以充分利用CPU资源。跟Serial垃圾回收器相同，Parallel垃圾回收器在进行垃圾回收时，也需要暂停应用程序的运行。Parallel垃圾回收器包含Parallel Scavenge（简称为PS）、Parallel New（简称为ParNew）、Parallel Old（简称为ParOld）三个细分的垃圾回收器。其中，Parallel Scavenge和Parallel New用于年轻代的垃圾回收，基于标记-复制算法来实现，Parallel Old用于老年代的垃圾回收，基于标记-整理算法来实现。Parallel Scavenge跟Parallel Old配合使用，Parallel New跟CMS配合使用。

CMS全称为Concurrent Mark Sweep。CMS垃圾回收器采用多线程执行垃圾回收，跟Parallel垃圾回收器所不同的地方是，CMS垃圾回收器在进行垃圾回收时，并不需要完全暂停应用程序，因此，STW时间更短。需要注意的是，CMS不能用于年轻代的垃圾回收。如果我们选择使用CMS垃圾回收器，那么，年轻代将默认使用Parallel New垃圾回收器。如果我们设置JVM参数-XX:-UseParNewGC，那么，年轻代将改用Serial New垃圾回收器。

CMS垃圾回收器将整个垃圾回收过程分为4个阶段：初始标记、并发标记、重新标记、并发清理。其中，初始标记和重新标记需要暂停应用程序，并发标记和并发清理可以与应用程序并发执行。对于CMS如何做到并发标记和并发清理的，我们在下一节中详细讲解。

CMS垃圾回收器在与应用程序并发执行的过程中会争抢CPU资源，因此，默认情况下，CMS使用的并发线程数等于(CPU内核数+3)/4。除此之外，CMS垃圾回收器在与应用程序并发执行的过程中也会争抢内存资源，因此，虚拟机在老年代没有完全存满之前就要进行垃圾回收，以便为并发执行的应用程序预留内存空间。

那么，到底老年代中已使用内存占比多少时，虚拟机就会进行垃圾回收呢？实际上，触发垃圾回收的内存占比是由虚拟机根据动态计算得到的。当然，我们也可以通过JVM参数-XX:CMSInitiatingOccupancyFraction来指定一个固定值，比如，我们设置-XX:CMSInitialOccupancyFraction=80，那么，当已使用内存占老年代的80%时，虚拟机便会触发CMS垃圾回收器的执行。不过，即便设置再合理的比例值，预留空间总会有不够用的时候，那么，此时虚拟机将中止CMS垃圾回收器的执行，转而使用Serial Old垃圾回收器进行本次垃圾回收。我们把这种情况叫做Concurrent Mode Failure。

除此之外，为了进一步减少STW时间，CMS采用标记-清除算法来实现，相对于标记-整理算法，省去了整理空闲空间的时间。前面讲到，标记-清除算法存在内存碎片问题，影响对象的内存分配效率。为了解决这个问题，CMS垃圾回收器对此进行了改进，在进行多次垃圾回收之后，会紧跟着进行一次内存碎片的整理。

G1全称叫做Garbage First。G1垃圾回收器是一个应用于整个堆上的垃圾回收器，它的实现方式跟其他垃圾回收器的实现方式有较大差别。

在上一节中，我们讲到分代垃圾回收算法会针对不同的分代采取不同的回收策略。分代垃圾回收避免了每次都对整个堆进行垃圾回收，缩短了垃圾回收的时间，进而缩短了STW时间。借鉴分代的处理思路，G1垃圾回收器将整个堆划分为很多（一般是2048个）小的区域（Region），其中，一部分区域归为年轻代（Eden区或Survivor区），一部分区域归为老年代，如下所示，各个分代中的内存并不是连续的。

之前的垃圾回收器都是针对整个分代进行垃圾回收的，要么是整个年轻代，要么是整个老年代，因为要回收的内存空间比较大，所以，垃圾回收时间也比较长。当年轻代和老年代被划分为更多更小区域之后，当进行垃圾回收时，虚拟机可以只回收分代中的部分区域，进一步缩短了STW时间。当然，G1垃圾回收器跟CMS垃圾回收器类似，也是使用多线程进行垃圾回收的，并且，回收的过程可以跟应用程序并发执行。在G1垃圾回收器中，年轻代的垃圾回收使用标记-复制算法，老年代的垃圾回收使用标记-清除算法。

跟其他垃圾回收器相比，G1垃圾回收器的STW时间是可预期的，我们可以通过JVM参数-XX:MaxGCPauseMillis设置可允许的最大STW时间。G1垃圾回收器会根据这个时间来决定每次对多少个区域进行垃圾回收。理论上讲，STW时间设置的越小，每次进行垃圾回收的区域就越少，垃圾回收的频率就越高。

以上介绍了4类常用的垃圾回收器，在默认情况下，Java7、Java8均采用Parallel垃圾回收器，Java9采用G1垃圾回收器。当然，我们也可以通过设置JVM参数来指定项目所使用的垃圾回收器。

在实际的项目中，我们该如何选择使用哪种垃圾回收器呢？

Serial垃圾回收器使用单线程进行垃圾回收，在多核系统下，它无法发挥多核的优势，但是，在单核系统下，因为其实现比较简单，相对于Parallel垃圾回收器，Serial垃圾回收器省去了线程切换的开销，执行更加高效，因此，Serial垃圾回收器常用于三种情况下：在单核系统下、多个应用程序争用CPU资源的情况下、需要刻意限制虚拟机所占用资源的情况下。比如，运行在移动端的客户端程序一般会采用Serial垃圾回收器，这类程序所占用内存空间往往比较小，并且垃圾回收不会耗时很多，因此，Serial垃圾回收器足够应付。

Parallel垃圾回收器跟CMS垃圾回收器相比，前者吞吐量更大，后者停顿时间更少。对于离线系统，我们首选吞吐量大的Parallel垃圾回收器。对于实时系统，特别是对响应时间比较敏感的系统，我们首选停顿时间更少的CMS垃圾回收器。不过，在Java9中，CMS垃圾回收器被标记为Deprecated（即不推荐使用），取而代之的是G1垃圾回收器。特别是对于堆比较大（大于6GB）的情况，我们应该首选停顿时间可控的G1垃圾回收器。

## 并发垃圾回收原理
停顿时间（即STW时间）是垃圾回收器非常关注的一个性能指标，为了尽量减少STW时间，CMS和G1垃圾回收器都实现了并发垃圾回收，也就是在不完全暂停应用程序的情况下，并发执行垃圾回收工作。那么，并发垃圾回收是如何实现的呢？

需要注意的是，这里所说的并发垃圾回收并非完全不需要暂停应用程序，而是在大部分时间里都不需要暂停应用程序。并发垃圾回收将垃圾回收的整个过程分为4个阶段：初始标记、并发标记、重新标记、并发清理。其中，并发标记和并发清理这两个比较耗时的阶段可以与应用程序并发执行，而初始化标记和重新标记这两个阶段仍然需要暂停应用用程序的执行。

初始标记指的是标记GC Roots，并发标记指的是在应用程序不暂停的情况下，以GC Roots为起点，广度优先或深度优先遍历所有可达对象（也即存活对象）。在并发标记的过程中，应用程序有可能修改对象之间的引用关系，导致并行标记过程出现误标或漏标的情况。重新标记所做的工作就是对误标或漏标进行修正。并发清理指的是在不暂停应用程序的情况下，对标记出来的垃圾对象进行清理。

在以上4个阶段中，初始标记、并发标记、重新标记这三个阶段属于可达性分析环节，也就是标记-清除算法中的标记环节。并发清理是标记-清除算法中的清除环节。接下来，我们就来详细讲解一下这4个阶段是如何实现的。

可达性分析基于三色标记算法来实现，它将遍历过程中的对象分别标记为：白色、灰色、黑色三种类型。各个颜色的含义如下所示。
* 白色表示对象没有被遍历过。在遍历开始时，所有的对象都是白色，但当遍历结束后，如果对象仍为白色，那么就表示对象不可达。
* 灰色表示对象已经被遍历但对象所直接引用的对象还没有完全被遍历。
* 黑色表示对象已经被遍历并且对象所直接引用的对象都已经被遍历。

前面讲到，可达性分析是基于图的广度或深度优先遍历算法来实现，我们拿广度优先遍历算法来举例讲解，在遍历的过程中，对象颜色的标记和转换具体如下所示。
* 将GC Roots标记为灰色并放入灰色集合，将其他节点标记为白色并放入白色集合。
* 从灰色集合中取一个灰色对象，将其标记为黑色并放入黑色集合，然后，将此对象直接引用的所有白色对象标记为灰色并放入灰色集合。
* 重复上述第2步，直到灰色集合中没有对象为止。此时，黑色集合中存放的就是可达对象，也就是存活对象，白色集合中存放的就是不可达对象，也就是死亡对象。

在上述的处理过程中，步骤1）被称为初始标记阶段，步骤2）和3）在并发垃圾回收中，可以与应用程序并发执行，因此，被称为并发标记阶段。

误标是可以接受的，它只会导致垃圾对象延迟回收，本该在本轮回收的对象在下一轮垃圾回收中被回收。漏标是不可以接受的，本不该被回收的对象被回收，这就会导致应用程序的运行出错，因此，漏标是重新标记要解决的重点问题。

我们总结一下漏标产生的原因，主要有以下两点。这两点缺一不可。
* 新增引用：新增一个黑色对象对一个白色对象的引用；
* 删除引用：删除所有灰色对象到此白色对象的直接或间接的引用。

针对以上两点，Java发明了两种漏标解决方案：增量更新和原始快照。实际上，这两种解决方案的处理思路是类似的，只不过，增量更新记录的是新增的引用关系，原始快照记录的是删除的引用关系。CMS垃圾回收器使用增量更新解决漏标问题，G1垃圾回收器使用原始快照解决漏标问题。

增量更新：在并发标记的过程中，如果应用程序新增了一个黑色对象对一个白色对象的引用，那么，虚拟机会将这个白色对象记录下来，在并发标记完成之后，重新标记阶段会以这些记录下的白色对象为起点，重新进行可达性分析。这样漏标的白色对象会被重新标记为黑色对象。

原始快照：在并发标记的过程中，如果应用程序删除了一个灰色对象对一个白色对象的直接引用或间接引用，那么，虚拟机会将这个白色对象记录下来，在并发标记完成之后，重新标记阶段会以这些记录下来的白色对象为起点，重新进行可达性分析。这就相当于虚拟机对引用关系改变之前的原始快照进行可达性分析。不过，使用原始快照记录下的白色对象有可能是死亡对象，而重新标记阶段会将这些死亡对象重新标记为存活对象，因此，原始快照这种解决方案会导致误标问题，不过，前面讲到，误标是可以接受的。

并发垃圾回收包括4个阶段：初始标记、并发标记、重新标记、并发清理。前面我们讲了前3个阶段，它们隶属于可达性分析，基于三色标记算法来实现。接下来，我们再来看下最后一个阶段：并发清理。为什么并发清理阶段可以跟应用程序并发执行？

在并发清理阶段，对象的引用关系也有可能发生改变。存活对象有可能会变为死亡对象，但这些对象只需要在下一次垃圾回收中被回收即可。反过来，死亡对象是否有可能会变为存活对象，从而导致清理操作将存活对象清理掉呢？

答案是不会。死亡对象不再有变量（局部变量或静态变量）的直接或间接引用，因此，应用程序是无法在代码中使用这些死亡对象。如下代码所示。函数内创建的对象，在函数内部可以使用，这是因为有局部变量的存在，我们可以通过局部变量来访问这个对象。但是，在函数执行结束之后，局部变量被销毁，没有变量直接或间接的引用这个对象，我们也就无法在代码中访问这个对象了。

有些读者可能会说，如果在并发清理的过程中，应用程序创建了新的对象该怎么办呢？实际上，解决方法很简单：直接将新创建的对象标记为黑色，即存活对象。这种处理方案同样适用于并发标记阶段。当然，这也有可能会导致误标问题。

## JVM 性能优化
既然要对JVM进行性能优化，那么，我们首先要知道如何评估JVM的性能。实际上，应用程序直接关注的性能指标主要就两个：GC频率和GC时间。当然，除了这两个性能指标之外，JVM内部还有很多更加细致的性能指标，如下所示，这些内部性能指标综合起来决定了GC频率和GC时间。
* 年轻代中对象的增长速率
* 每次 YoungGC 之后存活对象大小
* 每次 YoungGC 之后进入老年代的对象大小
* 老年代对象的增长速率

以上罗列的性能指标受JVM参数的影响。合理的设置JVM参数可以将GC效率发挥到极致，尽可能地减少GC对应用程序的影响。而不合理的设置JVM参数有可能引起JVM性能问题，比如频繁的FullGC、GC时间过长等。

JVM参数一般有3种类型：标准参数（以-开头，比如-version）、X参数（以-X开头，比如-Xint、-Xms2048m）、XX参数（以-XX开头，比如-XX:+PrintGCDetails、-XX:PermSize=512m），这类参数的稳定性依次下降，也就是说，在Java版本更新的过程中，标准参数很少改动，X参数有可能会改动，XX参数改动的可能性比较大。

JVM参数非常多，有上百个，但是，对绝大部分参数来说，默认的设置便是最普适、最合理的设置。除非真的有必要，否则，我们不应该主动去设置这些参数。常用的JVM GC参数只有几个，主要集中在内存分配和垃圾回收器的设置这两个方面，具体如下所示。

设置堆的大小
* -Xms：堆内存的初始大小
* -Xmx：堆内存的最大大小

一般情况下，我们会把-Xms和-Xmx设置为相同的值，以避免堆大小的调整而引起的性能损耗。

设置年轻代和老年代的大小
* -Xmn：年轻代大小；
* -XX:NewSize：年轻代的初始大小；
* -XX:MaxNewSize：年轻代的最大大小；
* -XX:NewRatio：年轻代与老年代的大小比值，比如-XX:NewRatio=4表示年轻代与老年代的大小比值是1:4，年轻代占整个堆大小的1/5。

设置年轻代大小的方式有多种：使用-Xmn、使用-XX:NewSize和-XX:MaxNewSize以及使用-XX:NewRatio。我们不需要显式地去设置老年代大小，将堆大小减去年轻代大小便可得到老年代大小。

设置永久代或元空间的大小
* -XX:PermSize：永久代的初始大小；
* -XX:MaxPermSize：永久代的最大大小；
* -XX:MetaspaceSize：元空间的初始大小；
* -XX:MaxMetaspaceSize：元空间的最大大小。

前两个参数仅在Java1.7及其以前版本中有效，后两个参数仅在Java1.8及其以后版本中有效。

设置Eden区和Survivor区的大小
* -XX:SurvivorRatio：Survivor区跟Eden区的大小比例，比如-XX:SurvivorRatio=8表示一个Survivor区跟Eden区的大小比例是1:8，也就是说，Eden区占年轻代大小的8/10，两个Survivor区分别占年轻代大小的1/10。

设置线程栈的大小
* -Xss：每个线程的栈大小，HotSpot JVM不区分虚拟机栈和本地方法栈，使用一个栈同时存储Java方法和本地方法的栈帧，因此这里只有一个栈大小的设置参数。线程栈大小默认为512KB或1MB。除非系统在运行的过程中出现非代码因素导致的StackOverflow，我们才需要调整线程栈的大小，否则，我们一般使用默认的线程栈大小设置即可。

设置垃圾回收器
* -XX:+UseSerialGC：使用Serial垃圾回收器；
* -XX:+UseParallelGC：使用Parallel垃圾回收器；
* -XX:+UseConcMarkSweepGC：使用CMS垃圾回收器；
* -XX:+UseG1GC：使用G1垃圾回收器。

刚刚我们介绍了常用的JVM参数，那么，如何设置合理的JVM参数呢？实际上，大部分情况下，我们只需要对常用的JVM参数，预设一些经验值，然后根据线上或者压测的情况，再做优化调整即可。当然，我们也可以事先预估一下系统对内存的使用情况，比如每秒钟产生多少对象，对象的生存周期等等，然后，依据期望的GC频率和GC时间，有针对性地设置JVM参数。具体如何来做我们通过一个例子来讲解。

我们对系统中调用频率最高的几个接口进行分析，罗列出执行每个接口请求所需要创建的对象大小，然后取平均值便粗略得到了执行一个接口请求所创建的对象的平均大小，假设这个值为2KB。我们预估系统的QPS是500，那么，我们就可以得知，系统每秒钟产生的对象大小大约1MB（500*2KB）。如果年轻代中Eden区和From Survivor区的总大小为1GB，那么，填满它们大约需要1000秒（即约16分钟），也就是说，系统每隔16分钟就会进行一次YoungGC。

我们再假设执行YoungGC会回收90%的年轻代空间，剩余100MB（1GB*10%）存活对象会被复制到To Survivor区。前面讲到，根据动态年龄判定机制，To Survivior区中的对象所占空间超过50%，就会导致部分对象进入老年代。为了尽量避免对象进入老年代而引发FullGC，我们需要保证To Survivor区大小至少为200MB。因此，年轻代大小应该设置为1.2GB。

我们再假设这100MB存活对象中，有10%的对象的生命周期特别长，会经过多次YoungGC之后进入老年代。也就是说，每次YoungGC会有大约10MB的对象进入老年代。假设老年代的大小约为1.8GB，并且每次垃圾回收只能回收老年代50%的空间，那么，每经过大约90次（1.8GB * 50% / 10MB）YoungGC就会执行一次FullGC，由此我们推出FullGC的时间间隔大约为24小时（90 * 16分钟 / 60）。

根据以上假设和分析，我们设置JVM参数，如下所示。这里假设系统名称为WebServer。因为系统对接口的响应时间比较敏感，因此，我们使用CMS垃圾回收器。年轻代的大小为1.2GB，为了保证To Survivor区大小至少为200MB，我们将-XX:SurvivorRatio设置为4。除此之外，存放类等元信息的元空间大小设置为512MB。线程栈大小使用默认值。
```shell
java -Xms3g -Xmx3g -Xmn1.2g -XX:MetaspaceSize=512m -XX:MaxMetaspaceSize=512m -XX:SurvivorRatio=4 -XX:+UseConcMarkSweepGC -jar WebServer.jar
```

不过，细心的读者应该已经发现，上述分析过程包含大量的假设，这就导致最终得到的JVM参数值可能并不准确，甚至完全没有意义，反倒不如经验值合理。实际上，初始JVM参数如何设置关系并不大，毕竟在项目上线或者压测的一段时间内，我们还需要密切关注JVM的表现，并且基于jstat等工具得到的JVM性能统计数据，进一步做性能调优。调优之后的结果才是最重要的。那么，具体如何进行JVM性能调优呢？

JVM性能调优的方向是减少GC频率和GC时间，特别是FullGC频率和FullGC时间。YoungGC时间往往都比较短，正常情况下，一般都在几毫秒或几十毫秒，对应用程序的影响很小，因此，YoungGC稍微频繁一点问题也不大。相比而言，FullGC要慢很多，正常情况下，一般都在几十毫秒或几百毫秒，对应用程序的影响较大。我们需要通过调整JVM参数，比如增大年轻代大小、增大Survivor区大小，让对象尽量在年轻代就被回收掉，减少老年代中对象的增长速率，从而降低FullGC频率。除此之外，增大老年代大小，也可以降低FullGC频率，当然这又会增大FullGC时间。

一般来讲，如果堆不是很大，那么，在没有长期存活的大对象和内存泄漏的情况下，应用CMS垃圾回收器并调节年轻代、老年代、Survivor区等的内存分配，完全可以将FullGC时间优化到合适的范围。如果实在不行的话，我们可以选择GC时间可控的G1垃圾回收器。

实际上，多久执行一次GC（YoungGC或FullGC）、一次GC（YoungGC或FullGC）耗时多久才算合理，并没有唯一的标准答案。具体值还是要看系统需求来定。如果系统并不在意STW时间，比如离线系统，那么，FullGC频繁一点、时间久一点，也问题不大。如果系统是响应时间比较敏感的系统，比如接口服务，那么，FullGC时间超过1秒就是不可接受的。

实际上，大部分情况下，经验值设置就已经满足绝大部分系统的需求，我们并不需要刻意的对JVM参数进行调优。只有当通过监控发现，GC的频率过大或GC时间过长，严重影响系统性能时，我们才有必要对JVM参数进行调优，具体的JVM参数调优方法以及辅助工具的使用，我们留在下一节讲解。

## JVM 问题排查
JVM的性能优化、参数调优一般都发生在JVM出现问题时，比如OOM、频繁GC、GC时间过长等。很多程序员面对这些JVM问题，除了重启系统之外别无他法。本节我们就来讲一下这些常见JVM问题的解决方案，以及排查问题过程中常用的JVM性能监控和分析工具。

用于JVM性能监控和分析的工具有很多，常见的有jstat、JConsole、VisualVM、jmap、MAT以及一些JVM参数。按照功能，我们将它们分为3类：GC统计信息监控、GC详细日志分析、JVM内存快照获取和分析，接下来，我们就按照类别简单介绍一下这些工具。
* GC统计信息监控：jstat、JConsole、VisualVM等
* GC详细日志分析：JVM参数-XX:+PrintGCDetails等
* JVM内存快照获取和分析：JVM参数-XX:+HeapDumpBeforeFullGC、-XX:+HeapDumpOnOutOfMemoryError、jmap、MAT、jhat等

**JVM 常见问题一：OOM**

导致内存溢出的常见原因有如下几种
* 设置的堆或者永久代（元空间）的大小太小
* 一次性创建过多的对象，比如通过 SQL 查询全表数据
* 应用程序使用完成的对象没有被及时释放，导致对应的内存无法被回收，长期积累便会导致内存耗尽。我们把这种情况叫做内存泄露。

当JVM出现OOM问题时，应用程序的对应表现一般是无法继续执行，如果应用程序是接口系统，那么接口将出现大量503错误。这时我们通过查看日志，便会发现大量的java.lang.OutOfMemoryError错误信息。为了排查出到底哪些对象长期存在并大量占用内存，我们需要通过jmap或JVM参数获取堆内存快照，并通过MAT等工具来查看和分析。

**JVM 常见问题二：频繁 GC**

一般来讲，在OOM出现之前，JVM会先出现频繁GC的现象。频繁GC包括频繁YoungGC和频繁FullGC。单纯的频繁YoungGC往往是由年轻代空间太小导致的，我们只需要适当增大年轻代的大小即可解决这个问题。

你可能会说，增大年轻代大小会不会导致YoungGC时间增长呢？实际上并不会。首先，年轻代采用的是标记-复制垃圾回收算法。标记（即可达性分析）只对存活对象进行遍历，而复制也只会对存活对象进行复制。因此，YoungGC时间只与存活对象的数量有关，与年轻代大小无关。其次，大部分对象都是朝生夕死，年轻代空间增大，YoungGC时间间隔增长，这会导致更多的对象在GC前就死亡，年轻代中的存活对象并不会明显增多。综合以上两点，YoungGC时间并不会随着年轻代的增大而增长。

相对于频繁YoungGC，频繁FullGC会引发更加严重的问题，且解决起来更加复杂。因为FullGC更加消耗CPU资源并且STW时间更长，所以，在发生频繁FullGC时，CPU利用率一般会飙升，并且会出现应用程序变慢的情况（比如接口请求处理速度变慢甚至大量超时）。

触发FullGC的主要原因是老年代空间不足。前面我们已经总结过，老年代的对象一般来源于长期存活的对象、大对象、空间分配担保。接下来，我们从这3个对象来源来分析频繁GC发生的原因。
* 长期存活的对象：如果应用程序创建的长期存活的对象比较多，那么，我们可以适当调大老年代的大小，以减少FullGC的频率。不过，这种情况并不常见，大部分应用程序并不会创建太多的长期存活的对象。实际上，内存泄露才是导致对象长期存活无法回收的主要原因。如果每次FullGC回收率很低，释放出来的空间很少，那么，这就说明是存在内存泄露了。频繁FullGC一段时间之后，JVM便会出现OOM。
* 大对象：过多的大对象是引起频繁FullGC的最常见的原因之一。比如，在某个接口中执行了未分页SQL，一次性加载过多数据到内存中。在高并发下，接口被大量调用，就会导致大量大对象被创建，从而导致老年代空间不足，引发频繁FullGC。定位此种频繁FullGC发生的原因，我们需要在FullGC前（设置JVM参数-XX:+HeapDumpBeforeFullGC）dump堆内存快照，分析占用堆内存比较多的是哪个对象，以此来定位问题代码。
* 空间分配担保：在执行YoungGC时，如果To Survivor空间不足，JVM会触发空间分配担保，将对象存储到老年代。因此，如果每次YoungGC，To Survivor都被占满，那么，我们就要考虑增大To Survivor区，避免空间分配担保，减少进入老年代的对象数量。

**JVM 常见问题三：GC 时间过长**
* 堆内存过大：年轻代使用标记-复制垃圾回收算法，并且，年轻代空间增大并不会导致存活对象增多，因此，YoungGC时间跟年轻代的大小无关，但是，老年代使用标记-整理或标记-清除垃圾回收算法，并且，老年代空间增大会导致存活对象增多，因此，FullGC时间跟老年代的大小有关。老年代过大会导致FullGC时间过长。针对比较大的堆内存，我们应该选择GC时间可控的G1垃圾回收器，或者在一台大物理内存的机器上部署多个JVM以减小单个堆内存的大小。
* Concurrent Mode Failure：CMS垃圾回收器采用并发垃圾回收算法，在垃圾回收的某些阶段，应用程序可以与之并发执行。应用程序的执行需要堆内存，因此，JVM在执行垃圾回收前，会预留一定的堆内存空间。但是，在执行垃圾回收的的过程中，如果预留空间不足，应用程序无法继续执行，那么，JVM便会抛出Concurrent Mode Failure错误，并且，暂停CMS垃圾回收器的执行，改为STW时间更长的Serial Old垃圾回收器。垃圾回收器的中止和切换势必会增长FullGC时间。如果我们在GC详细日志中（通过设置JVM参数-XX:+PrintGCDetails得到）发现大量Concurrent Mode Failure字样，那么，我们就需要通过减小JVM参数-XX:CMSInitialOccupancyFraction的值来调大预留空间的大小。
* 操作系统 swap：swap是操作系统中的概念。当物理内存不足时，操作系统会将物理内存中的部分不活跃的数据放入磁盘，当这部分数据重新被使用时，再从磁盘加载到物理内存中。这种数据在物理内存和磁盘之间换入换出的机制，就叫作swap。swap涉及磁盘I/O操作，非常影响进程的性能。如果设置的JVM堆内存大小超过物理内存大小，或者多个应用程序争用有限的物理内存，那么，这就有可能触发swap而导致GC时间增长。解决这个问题的方法也很简单，尽量保证JVM堆大小不要超过物理内存的大小，并且为操作系统和其他软件预留充足的物理内存，比如物理内存有8GB，我们设置JVM堆大小为6GB，预留2GB给操作系统和其他并发运行的软件。