## 负载均衡
负载均衡的核心工作原理可以概括为：流量分发+智能调度。

负载均衡是大型分布式系统架构的必备组件，以下是它常常出现的地方
* Web 服务入口：这是最常见的，用于通过域名访问应用，流量首先打到负载均衡器（比如 Nginx），再由它分发给后面的多个 Web 服务器
* 微服务网关：在微服务架构里，API 网关本质上就是一个强大的七层负载均衡器，负责将外部请求路由到内部各个微服务实例
* 数据库/缓存访问：为了实现数据库读写分离、主从集群、缓存集群等数据分片，客户端或者中间件通常利用负载均衡策略来分发请求
* 内部服务调用：服务 A 要调用服务 B，服务 B 有多个实例。服务注册中心（如 Eureka, Consul, Nacos）配合客户端（比如Dubbo client）集成的负载均衡逻辑，就能实现服务 A 到服务 B 实例间的智能负载均衡。

对于Web服务的负载均衡，负载均衡主要解决哪些具体的问题呢？或者说可以起到什么作用呢？我们做了一些总结，如下所示。
* 单点故障：如果只有一台服务器，万一它挂了（硬件故障、软件崩溃、机房断网），整个服务瞬间全停，用户直接“凉凉”。单点故障是线上系统的大忌。负载均衡后面挂着多台服务器，一台服务器挂了，负载均衡马上就能把流量导到其他健康的机器上，用户可能都感觉不到异常。消灭了单点故障，高可用性提高了。
* 性能瓶颈：一台服务器的能力（CPU、内存、磁盘IO、网络带宽）是有上限的。用户少的时候没事，用户一多，或者请求一复杂，它就可能顶不住了，响应时间飙升甚至拒绝服务。负载均衡把请求分散到多台机器上，相当于大家合力干活。水平扩展性，用户再多，加机器就行。
* 水平扩展：用户的访问量通常不是一成不变的，有高峰有低谷。如果按高峰配置单台超强服务器（垂直扩展），低谷期它就闲置浪费了。用负载均衡配合一堆普通配置的服务器，可以根据流量动态调整机器数量（弹性伸缩），高峰加机器扛住，低谷减机器省钱。资源利用率更高，成本更优。

一般来讲，一个请求就会对应着一个响应，按照响应是否经过负载均衡器，以及负载均衡器工作的环境（内网还是外网），负载均衡器一般有三种工作模式：NAT、DR、TUN。
* NAT 工作模式：在这种工作模式中，请求数据和响应数据都会经过负载均衡器，Nginx就是这种工作模式。
* DR 工作模式：在这种工作模式中，请求数据经过负载均衡之后被改写，后端服务器收到请求之后，将响应数据直接返回给客户端，而不经过负载均衡，后面讲到的F5、LVS等都支持这种工作模式。
* TUN 工作模式：TUN工作模式跟DR工作模式类似，响应数据都不经过负载均衡器。区别在于，它们的处理逻辑不同，导致DR只能工作在内网内，而TUN模式可以在广域网内工作，因此，TUN一般应用于多机房之间的负载均衡，比如异地多活。

除了以上工作模式之外，负载均衡根据其路由决策使用的数据处于ISO网络分层中的哪一层，又分为了L4层负载均衡和L7层负载均衡。像后面讲到的LVS就是L4层负载均衡器，Nginx是L7层负载均衡器，F5、HaProxy既可以工作在L4层，又可以工作在L7层。

L4 负载均衡进行路由决策的依据是：**IP和端口**。在ISO网络分层模型中，IP为L3网络层的概念，端口为L4传输层的概念。负载均衡器主要看请求是哪个 IP 发来的（源 IP）、目标是哪个 IP 和端口（目标 IP:Port）。它不怎么关心请求里具体是啥内容（比如 HTTP 请求的 URL 或 Header）。


L4层负载均衡最大的特点就是：速度快、效率高，因为它处理的信息少，就像快递分拣只看邮编和街道，不拆包裹看里面是啥。适合对传输速度要求高、不需要根据内容做精细路由的场景，比如数据库连接、游戏服务器、简单的 TCP/UDP 应用。

L7层负载均衡**根据ISO网络模型中第七层应用层的数据做路由决策**。也就是说，调度员会“拆开包裹”看看里面的内容，再决定如何投递。对于 HTTP请求，它会解析 URL 路径、HTTP 头信息（如 Host, Cookie, User-Agent）、甚至是请求体内容。

它的优势是功能更加强大、更智能、更能贴合业务的路由需求，可以实现非常精细的路由策略。比如基于URL的路径进行路由到不同的微服务上，将包含特定Cookie（比如version=beta）的请求导到测试环境，甚至还可以做简单的请求改写（比如加/减 Header）。

负载均衡器本身可以是一个专门的硬件设备（比如F5等），也可以是软件（比如Nginx, HAProxy, LVS 等），甚至可以是集成在服务框架里的（比如 Spring Cloud Gateway + Ribbon），甚至还可以是DNS。

DNS 负载均衡：我们知道DNS负责域名解析，将域名解析为IP返回。实际上，一个域名可以配置多条IP解析，DNS可以根据轮询或者随机返回一个域名请求对应的IP，当然，也可以根据地理位置就近原则（比如，国内IP对域名的访问，DNS会返回国内的服务器IP）或者通信线路（移动、联通、电信等）返回不同的IP。实际上，DNS只能算是“伪负载均衡”，它无法替代其他真正的后端负载均衡器，只能实现全局入口流量的调度。

硬件负载均衡器是特制的硬件（硬件加速、专用芯片），是企业级高性能的首选，当然，价格相对于软件负载均衡，也更加昂贵。代表的产品有F5 BIG-IP、深信服AD系列、A10 Networks等。

对于L4层负载均衡器，表征性能的指标主要有CPS（Connections Per Second，每秒新建TCP连接数）和并发连接数（主要利用内存资源）。其中，F5可以达到几百万级别的CPS和几千万级别的并发连接数。有同学可能会说，不需要考虑吞吐量吗？实际上，吞吐量大多数情况下主要受限于网络带宽，而非负载均衡本身。

高CPS和并发连接数在以下场景中可以发挥作用：
* 海量短连接业务，如即时通讯（如微信）、物联网设备心跳上报，连接建立频繁。
* 长连接流量洪峰，如视频直播推流、数据库代理，初始连接建立压力大。
* DDoS防御层，抵御SYN Flood攻击需高CPS处理能力。

软件负载均衡：LVS、HAProxy、Nginx都是软件负载均衡，不同的地方是，LVS是L4层负载均衡，Nginx是L7层负载均衡，HAProxy既可以工作在L4层，也可以工作在L7层。相对于硬件负载均衡器，软件负载均衡在性能上要稍逊色一些，但价格要便宜太多，只需要部署在一台普通的服务器上就可以。对于L7层负载均衡，表征性能的指标除了刚刚提到的每秒新建连接数和并发连接数之外，还有一个新的指标：QPS。QPS是ISO网络模型中第七层应用层的概念。

文章最开始我们提到，负载均衡的核心工作原理可以概括为：流量分发+智能调度。前面都在讲流量分发，接下来，我们再讲一下智能调度。负载均衡会依赖不同的策略，将流量分配给不同的后端服务器，这里的策略就是负载均衡算法，是在负载均衡器中预设置好的。常用的负载均衡算法有以下几种：
* 轮询：这是最公平的流量分配算法，将请求按顺序依次分配给后端服务器列表中的每一个服务器，循环往复。
* 加权轮训：：考虑后端服务器性能差异，为了让性能好的服务器多承担一些流量， 在轮询的基础上，为每台服务器分配一个权重值（Weight）。权重高的服务器被分配到的流量比例更高。分配时按权重比例进行轮询。
* 哈希：基于源IP地址或者URL，又或者业务信息，通过计算哈希值，然后跟服务器个数取模，得到请求对应的服务器编号，将请求分发给这个服务器。
* 最小连接：负载均衡实时获取后端服务器的负载，这里的负载通过连接数来表征，将请求分发给负载最小的后端服务器，以达到各个服务器的负载均衡。相对于前面几种静态负载均衡算法，这是一种动态负载均衡算法。
* 最短响应时间：负载均衡实时获取后端服务器的响应时间（某段时间内的平均响应时间），将请求分发给响应时间最短的服务器。这也是一种动态负载均衡算法。

对于网站应用来说，如果QPS小于1万，正好在一台Nginx的处理能力之内，可以只使用Nginx或者HAProxy做负载均衡就可以了。如果QPS大于1万，可以先用LVS做L4层负载均衡，后端挂在多个Nginx做L7层负载均衡，Nginx再挂在后端服务器。当然，如果是大型企业级高可用的应用，也可以使用成本很高的硬件负载均衡器，比如F5，替代LVS。

除此之外，我们还可以先通过DNS做入口流量根据地理位置的分流，然后再通过LVS->Nginx->Tomcat服务器，实现更多层的流量负载均衡。

## 系统通信
在分布式系统中，通信无处不在。比如，业务系统与Redis之间的通信，业务系统作为Producer或者Consumer与MQ（消息中间件）的Broker之间的通信，以及业务系统之间的互相通信，还有业务系统与客户端（Web前端、APP客户端等）之间的通信。

### 长连接 VS 短连接
我们刚刚提到了一些分布式系统中的常用组件，它们的通信方式的主要区别，在于应用层协议（比如，HTTP协议、MySQL协议、Redis协议、Dubbo协议、RocketMQ协议）和连接管理方式的不同。应用层协议可以简单理解为数据格式的定义，每个组件都不同，我们不展开讨论。连接管理方式可以分为短连接和长连接。

不管是短连接还是长连接，它们在网络传输层最终都要依赖操作系统提供的 TCP Socket API 来建立连接、发送和接收数据。Socket 是操作系统提供的网络通信的编程接口，TCP 是可靠的、面向连接的传输层协议。

短连接就像每次打电话都重新拨号。客户端和服务器每进行一次数据交换，就建立一次连接，传输完毕立即断开。典型的例子是HTTP/1.0。每次请求都需要三次握手建立连接，传输数据，再四次挥手断开连接。这种方式简单直接，但频繁建立和断开连接消耗大量资源，在高并发场景下效率低下。

长连接则像保持电话畅通。一旦建立连接，就会在多次数据传输中重复使用，直到空闲超时或主动关闭。例如，HTTP/1.1的Keep-Alive机制、数据库连接池、RPC框架的底层通信，都是长连接的典型应用。**长连接避免了反复握手的开销，显著提升了性能，但需要额外的心跳机制来维持连接活性，防止被防火墙或运营商切断**。

我们再来看开头提到的一些系统通信：RocketMQ的Producer跟Broker之间是长连接，可以持续发送消息；在Push工作模式下，RocketMQ Consumer跟Broker之间也是长连接，但在Pull工作模式下，这两者之间是短连接；MySQL Client跟MySQL Server之间是短连接，一个SQL执行完之后，连接立即释放，但当使用连接池管理连接之后，连接池用池化技术模拟出“逻辑短连接”（用完之后就“释放”），底层实际是物理长连接。Redis Client跟Redis之间的连接也是如此。

实际上，**大部分基础组件一般都会采用长连接进行通信，保证通信性能足够高**。但是，对于服务间以及端到服务间的通信，到底选择使用短连接还是长连接，需要根据具体的业务需求来决定。接下来，我们就来详细讲讲服务间以及端到服务间的通信方式。

### HTTP 接口 VS RPC
在我们的业务开发中，常见的业务系统间的通信方式有两种，一种是直接接口调用，另一种是发送异步消息。异步消息通过消息中间件实现，我们后面再详细讨论。这节课我们聚焦第一种通信方式：接口调用。而接口调用又主要有两种实现形态：HTTP接口和RPC调用。

HTTP接口基于我们熟悉的HTTP协议，通常以RESTful风格设计。它的最大优势是通用性。任何语言、任何平台，只要支持HTTP就能调用。比如，Java服务通过Spring Boot暴露HTTP接口，其他语言可以直接使用HTTP client来调用Java服务提供的接口，接口的调用方并非局限于Java这一种语言。此外，HTTP接口调试方便（用curl或浏览器即可），这些特性让它成为跨团队、跨系统、跨语言对接的首选。但HTTP协议基于短连接通信且使用文本传输（如JSON）数据，效率较低，在高性能场景下可能成为瓶颈。

我们再来看RPC（Remote Procedure Call）调用。它让远程调用像本地方法调用一样简单。比如Dubbo、gRPC这类框架，会生成代理对象，开发者直接调用接口方法，框架自动完成网络传输。RPC通常采用二进制协议（如Protobuf），传输效率极高，且内置服务发现、负载均衡、熔断降级等治理能力（这个我们后面再详细讲）。但RPC的代价是语言绑定性强，虽然gRPC支持多语言，但整体生态仍不如HTTP开放。调试也更复杂，往往需要专用工具。

对于外部服务来说，也就是我们前面提到的端到服务之间，我们一般选择使用基于短连接的HTTP来实现接口。一般一个用户的操作可能不会很多，也不会很频繁，比如1s一次，操作完就结束了，没必要使用长连接。而且，因为用户数量巨大，长连接的方式是对后端系统并发连接能力的一个很大挑战。

而对于内部服务来说，也就是我们前面提到的服务间通信，我们倾向使用基于长连接的RPC来实现接口，毕竟调用方与服务方之间的总连接数比较有限，并发连接数并不会成为压力。而对于一个大平台来说，内部服务拆分会非常细、非常多，一个业务逻辑请求可能会涉及到n个系统的n个接口，为了保证整个长链路的性能，内部系统之间交互最好使用性能更好的RPC长连接。

## Web 容器
如果聚焦到Web应用，对于HTTP请求来说，后端服务器需要解析HTTP请求中的JSON等序列化数据，转换成后端编程语言中的对象，然后找到请求（URL）对应的业务逻辑代码（类及其方法），最终执行之后，将对象形式的执行结果，转换成JSON等序列化数据，封装到HTTP Body中返回。

这一处理流程，实际上是跟业务代码无关的，程序员没必要每次都重复编写，我们完全可以将这部分非业务功能代码抽离出来，做成独立的框架（内嵌式Web容器）或者系统（独立部署Web容器），于是就有了Web容器。

根据存在形式和使用方法，我们可以将Web容器简单分为独立部署Web容器和内嵌式Web容器两类。
* 独立部署Web容器指的是需要预先安装并独立运行的Web服务器环境，应用程序需按特定规范编写并打包部署。Tomcat是典型的独立Web容器：开发者按照Servlet协议编写代码，打包为WAR文件后，部署到Tomcat的webapps目录下，由Tomcat容器加载并执行。
* 内嵌式Web容器：指的是将Web服务器功能直接集成在应用代码中，编译后形成自包含的可执行文件。Go语言的net/http包就是内嵌式Web容器，使用net/http开发的业务代码，编译成单一二进制文件后直接运行，即可启动完整Web服务，无需外部容器支持。

实际上，在Java生态中，Spring Boot框架也提供了内嵌式方案：通过内嵌Tomcat容器，使开发的应用可直接通过运行 java -jar 启动，无需部署到独立Tomcat实例。

Web 容器主要功能
* 动态请求处理
* 协议解析与封装：Web 容器将原始 HTTP 字节流转化为编程语言可操作的对象，还会统一处理连接复用（Keep-Alive）、分快传输编码（Chunked Encoding）等网络传输协议细节，是开发者无须关心底层网络通信。如Java的Tomcat通过HttpServletRequest和HttpServletResponse对象封装请求/响应、Go的net/http包提供http.Request和http.ResponseWriter接口操作数据、Python的Django框架则构建HttpRequest对象承载请求上下文。
* 请求-响应生命周期管理：Web 容器提供了请求从接受到响应的完整生命周期管理，我们在编程时，无须关心请求到响应的处理流程，只需要在 Web 容器预留的钩子中，编写业务逻辑代码即可，这有点类似模板设计模式。
* 并发模型设计：后端服务必须支持并发请求，也就是，同一时间处理多个请求。这样的需求就要求 Web 容器必须具备并发接受 HTTP 请求，以及并发执行业务逻辑的能力。一般来讲，Web容器可以采用epoll等操作系统底层的socket轮训机制，来实现支持高并发连接，使用线程池（Java Tomcat）、协程（Go net/http）、异步事件（Python的ASGI容器）来实现并发执行业务逻辑。

刚刚我们对Web容器做了简单的介绍，介绍了其核心职责，其中一项是并发模型，这里我们就展开重点讲一讲。为了言之有物，我们聚集到Java的Tomcat Web容器来举例讲解。
并发模型-maxConnections：指的是可以有多少客户端同时连接到 Web 容器，在网络层面就是 TCP 连接数，在操作系统的 socket 编程层面，就是同时建立连接的 socket 个数。并发连接主要消耗内存和操作系统的文件描述符个数，如果单独考虑这个值的话，理论上讲，它可以很大很大。但是，这个值又受制于“并发线程数”（maxThreads）。如果并发连接数很大，但是并发线程数很小，大量的请求来袭，但来不及执行，就会导致大量请求阻塞、超时、或被拒绝。

对于短连接请求，连接上之后就发送请求，发送完就结束连接，并发连接数设置的稍大于并发线程数（比如3 ~ 5倍，大一点是为了起到缓冲请求的作用）就可以了，太大了服务不了，也没有意义。但是，对于像Websocket这种长连接请求，尽管大量客户端连接着后端服务器，但是发送请求的频率却很低（比如每秒1次，对于服务器来说算低了）。连接虽多，但请求不多，在这种场景下，为了支持大量客户端同时连接，就可以将并发连接设置的比并发线程数大很多（比如50 ~ 100倍）。

不过，我们发现，默认Tomcat的maxConnections设置为10000，maxThreads设置为200。为什么maxConnections默认要设置如此大呢？其实，这也说明一个问题，maxConnections大点也没啥问题，毕竟线程服务不了就拒绝嘛，早拒绝（连接时就被拒绝）还是晚拒绝（获取线程去执行业务逻辑时被拒绝）都是拒绝，也没啥影响。

当然，maxConnections设置的太大也不是没有成本的，每个socket都会对应有接受缓冲区和发送缓冲区（总共128KB的样子），maxConnections设置太大（设置10000的话消耗至少1.28GB）会消耗过多内存，因此，如果内存有限，又无需支持WebSocket，建议将这个值调低。

并发模型-maxThreads

对于CPU密集型程序，对应的线程池不需要太大，跟可用CPU核数相当或稍大即可。这样便可以充分的利用CPU资源。对于I/O密集型程序，因为程序的大部分时间都在执行I/O操作，所以，CPU利用率很低。为了提高CPU的利用率，我们可以将线程池适当开大点，以便多个线程轮流使用CPU。那么，既非CPU密集又非I/O密集的程序，对应的线程池大小又该如何设置呢？有没有具体的计算机公式可以给出线程池大小的确切值呢？

从理论上来讲，确实存在这样的计算公式。假设通过监控统计，我们得知线程池所执行的任务的平均CPU耗时和平均I/O耗时（确切的讲应该为非CPU耗时，但是，大部分非CPU耗时一般都花费在I/O上，因此，这里就直接使用I/O耗时代指非CPU耗时），那么，线程池大小的计算公式就应该如下所示。
```shell
并发线程数 = CPU核数 × 目标CPU利用率 × (1 + 平均I/O时间 / 平均计算时间)
```

比如，某订单服务，统计接口的平均响应时间50ms，其中，等待DB/Redis等的I/O时间为45ms（I/O等待占比90%），CPU计算时间为5ms。除此之外，CPU为8核，目标CPU利用率通常为70%~80%（留余量防突发流量），带入公式得到：
```shell
并发线程数 = 8核 × 0.8 × (1 + 45/5) = 8 × 0.8 × 10 = 64
```

不过，这个计算公式过于理想化，它默认I/O资源是无限的。这也是只会背八股文的程序员在面试时经常犯的错误。实际上，这个公式计算的是：CPU在充分利用的情况下的并发线程数，但是，有可能CPU还没有达到充分利用，其他资源（数据库连接池、磁盘IOPS、网络带宽、内存的大小）就已经到达瓶颈了。

假设服务的执行依赖数据库，数据库连接通过数据库连接池来管理，假设数据库连接池的大小为N，那么，当线程数大于N时，数据库连接就成了瓶颈资源，多出来的线程需要等待数据库连接，整体的执行效率也不会提高，反倒可能会因为线程的频繁切换，而影响性能。对于存在瓶颈资源的服务来说，在计算或者估计线程池大小时，我们不能再以充分利用CPU为目标，而是应该以充分利用瓶颈资源为目标。也就是说，线程池大小应该设置为跟数据库连接池大小相当才算合理。

> 因此，在实际的架构设计中，我们必须建立全链路的资源视图，绘制请求处理所经过的所有链路，找出链路上核心节点的承载能力，确保线程池大小不超过路径上的最小承载能力。

### 并发模型-Go携程
Go语言的Web容器采用基于Goroutine（协程）的并发模型，这与Tomcat的线程池模型有本质区别。Goroutine是Go语言的轻量级用户态线程，其核心优势在于：
* 极低资源开销：每个Goroutine初始栈仅2KB（可动态扩缩），远小于Java线程栈1MB，单从内存上看，单机可轻松支撑数十万并发。
* 非阻塞调度：当Goroutine执行I/O操作时（如数据库查询），Go运行时会自动将其挂起，调度其他Goroutine运行，避免线程阻塞。
* 协程切换开销很小：Go协程可以看做用户级线程，切换只发生在用户态，相对于Java线程切换（涉及内核线程的切换）来说，要快很多，Java线程切换可能需要几微秒（取决于CPU等硬件性能），而Go协程的切换可能只需要200纳秒左右，具有十倍的性能优势。

也就是说，Tomcat在设置线程池大小的时候，需要考虑内存消耗、线程过多导致频繁切换开销这些因素，而对于Go Web容器来说，完全就不需要考虑这些问题了。但是，这是不是意味着Go Web容器就可以无限创建很多很多协程去处理请求呢？当然不是！因为还有其他资源限制，比如数据库连接池、Redis连接池、磁盘IOPS、网络带宽等等。

如果有大量请求到来，Tomcat处理不了（超过maxThreads设置的处理上限），就会抛出HTTP 503拒绝服务，相当于一种fail fast策略，起码能保证剩下的请求正常响应。但是，Go Web容器会持续创建协程，但是，会有大量的请求阻塞在等待数据库连接池等瓶颈资源，导致超时。而拒绝比超时更明智，因为等待超时的请求需要长时间占用内存等资源直到超时，而拒绝会立即释放资源。

这样看来，Tomcat天生提供的maxThreads配置反倒是一种优势，相当于一种限流机制。相反，Go的“无限协程”只不过是把资源管理的责任转嫁给开发者罢了。**开发者仍需用channel+select实现限流，或用semaphore.Weighted控制并发度**。

## KV 数据库
简单，所以快。 没有复杂的表连接，没有多表事务（或者事务支持很有限），没有模式（Schema）约束（Value 的结构可以很灵活，可以是字符串、数字、二进制 blob，甚至是 JSON、Protocol Buffers 序列化后的数据）。这种“轻装上阵”的特性，让 Key-Value 数据库在读写速度上，尤其是简单查询（根据 Key 查 Value）的性能，通常能碾压传统的关系型数据库。毫秒级甚至微秒级的响应很常见，特别适合那些对延迟极度敏感的场景，比如缓存（Redis、Memcached 就是典型的 Key-Value 缓存）、会话存储。

持久化与内存之争。 Key-Value 数据库在存储引擎上也有不同侧重。一部分，比如 Redis，主要设计目标就是超高速访问，数据主要放在内存里（当然可以配置持久化到磁盘防止重启丢失）。这使它成为缓存、实时排行榜、消息队列等场景的王者。另一部分，比如 RocksDB（嵌入式引擎）、LevelDB，或者基于它们构建的分布式系统（如 TiKV），则更侧重于海量数据的持久化存储和高吞吐写入。它们利用像 LSM-Tree 这样的数据结构，将随机写转换为顺序写，并高效地合并压缩数据文件，在保证不错读取性能的同时，能处理远超内存大小的数据量，常用于分布式数据库的底层存储或需要持久化 KV 的场景。

Redis 能达到 10万+ QPS 和 亚毫秒级（零点几毫秒）延迟的高性能，性能是MySQL的十倍以上。如此高性能主要得益于以下几点：
* 仅内存读写，无磁盘读写（磁盘随机读延迟约 10ms，内存读仅 0.1μs）；
* 单线程避免了线程切换和锁竞争导致的性能开销；

前面提到，Redis是单线程模型，也就是单线程执行命令，那么，如果机器的CPU是多核的，比如8核，在机器上部署一个Redis实例，这个Redis实例只会使用1个CPU核，其他CPU核都闲置了，怎么能充分利用CPU核呢?

解决办法也很简单，我们可以在一台机器上部署多个Redis实例，比如8个Redis实例，这样就能充分利用CPU资源。但是，QPS跟实例个数并不成线性关系。因为随着单台机器上Redis实例的增多，内存和网络慢慢也会成为瓶颈。如果单个Redis实例的QPS为12万，理论上讲，8个Redis实例总的QPS应该是96万。但是，对于DDR4-3200（双通道）内存来说，它的读写速度的上限是50GB/s，8个Redis实例并发读写内存，争抢使用内存通道，其对读写速度的需求远超过50GB/s。除此之外，8个实例共用CPU的L3缓存，也会导致缓存频繁失效，也会严重影响性能，不仅QPS不会随着Redis实例的增多而线性增长，反而读写的响应时间会延长。

对于在8核机器上具体应该部署几个Redis实例，我们要经过压测以及监控，递进地增加Redis实例个数，找到性能挂点，即增加Redis实例也不会增长QPS，反倒会性能下降的临界情况，这时的Redis实例个数就应该是单机部署的Redis实例个数的上限。

虽然Redis性能非常高，但是，单台机器的内存是有限的，对于大规模互联网应用，如果我们希望存储海量的数据（远大于单台机器的内存大小）并且支撑更大的QPS（比如100万QPS），单机无法满足对内存和QPS的需求，我们就要走分布式路线，也就是，对Redis进行水平扩展，更确切的说，应该是**数据分片**（sharding）。

我们知道，关系型数据库，比如MySQL，虽然可以通过主从**读写分离、分库分表**来扩展，但这通常比较复杂，且分库分表后对跨分片事务和复杂查询支持困难。而Key-Value数据库恰恰相反。因为它只提供简单的读写操作，并且数据存储结构也很简单（一个Key对应一个Value），因此，天生易于水平扩展，只需要基于Key做分片，配合哈希算法，就可以实现无损的无限扩展。

> 微博就采用128个分片的Redis集群，实现了超大内存（120TB），峰值QPS支撑2100万，平均读写延迟在0.9ms，P99为5ms。可见，Redis是应对海量数据高性能读写的利器

Redis 高可用架构
* 主从复制：也就是经典的master-slave架构，数据写入master，然后异步复制到一个或者多个slave，既可以让master负责读写，slave负责备份，也可以让master负责写，slave负责读。不过，当master宕机之后，需要人工干预手动切换从节点为主节点，这就会导致有一定的不可用时间。
* 哨兵模式：相对于主从复制架构存在的需要人工手动切换主从节点的问题，Redis提供了哨兵模式，通过哨兵监控主从节点，并且实现自动故障转移，即主节点宕机后，通过Raft算法自动选举从节点为主节点。客户端通过哨兵（sentinel）获取新的主节点的地址。
* Redis Cluster：在Redis Cluster中，每个分片都有主从节点，并且实现了故障自动转移，主节点宕机之后从节点自动接替。

Redis 应用场景
* 缓存
* 会话存储
* 高性能计数器
* 消息队列（发布订阅）
* 排行榜
* 签到统计
* 点赞
* 最新动态
* 共同关注
* 购物车
* 延迟队列

## 关系数据库
关系型数据库也可以叫做SQL数据库，使用SQL语言作为与数据库的交互语言。它存储的是结构化的数据。所谓结构化的数据指的是数据具有预定义的模式（Schema），所有记录遵循相同的字段结构。数据以二维表形式组织：行存储单条记录，列存储字段值，表内可定义约束（如唯一性、数据类型、长度限制），表间通过外键建立关联。

关键特性
* 强一致性事务：关系型数据库通过ACID特性支持强一致性事务，这是其他数据库为了追求性能所不具备的，这一特性极好的满足了业务开发中某些关键业务对事务的强一致性要求。比如银行转账确保扣款与入账同时成功。其实，后面我们讲到最终一致性解决方案时，其常用的基于本地消息表、消息队列的解决方案，也是依赖数据库的强一致性事务支持的！
* 复杂关联查询：关系型数据库通过SQL语句以及结构化的存储结构，支持JOIN操作跨表关联查询、嵌套子查询、聚合函数（SUM/AVG）、分组统计（GROUP BY）、排序（ORDER BY）等复杂查询，方便开发者通过SQL一次性获取足够的数据。对比来说，Key-Value数据库仅支持简单的命令操作，关联查询需多次往返客户端拼接数据，效率低下且一致性难保障。
* 结构化数据存储：关系型数据库通过字段类型、长度、非空、唯一性等规则，强制保障数据质量（如手机号必须是11位数字），避免非法数据入库（如字符串写入整数字段），提升业务开发效率，ORM框架（如MyBatis）自动映射表结构到对象。对比Key-Value数据库，KV库无固定结构（如Redis的Value自由格式），需业务层解析数据，易出现脏数据或解析错误。

存储引擎是MySQL的核心组件，它决定了数据如何存储、读取、更新和删除。MySQL常见的存储引擎有InnoDB和MyISAM。MySQL采用插件式架构，允许你为每张表选择合适的存储引擎。

InnoDB默认引擎，因其支持事务并且是行级锁，锁定粒度是行级（默认），大大提高了多用户并发环境下的读写性能（尤其是写操作），减少了锁冲突。而MyISAM不支持事务，并且是表级锁，对整个表加锁（读锁或写锁）。写操作会阻塞所有其他读写操作，并发性能差，尤其在写入频繁的场景下。对于只读或读多写少且不需要事务的场景，其简单设计有时能提供比InnoDB更快的纯读取速度。

除非有非常明确且合理的理由选择其他引擎，否则，我们在开发中一般首选InnoDB引擎。在存储引擎中，有一个非常重要的数据结构，那就是索引。索引是保证数据库快速查找数据的关键。

ACID是保证数据库事务可靠性的四个关键属性，确保即使在系统故障或并发操作的情况下，数据库事务也能正确执行。InnoDB是MySQL中支持完整ACID事务的主要存储引擎。我们依次来看下A、C、I、D这四个特性。
* 原子性 Atomicity：原子性指的是，一个事务（Transaction）被视为一个不可分割的最小工作单元。事务中的所有操作要么全部成功执行（提交 - Commit），要么全部失败回滚（回滚 - Rollback）。不存在部分执行的状态。比如转账操作：从A账户扣钱和向B账户加钱必须同时成功或同时失败，不会出现扣了A的钱却没加到B账上的情况。原子性的实现机制主要依靠 undo log (撤销日志)。当事务需要回滚时，InnoDB利用undo log中记录的信息（旧版本数据）来撤销该事务所做的修改。
* 一致性 Consistency：事务的执行必须使数据库从一个一致的状态转换到另一个一致的状态。一致性是指数据库的完整性约束（如主键唯一、外键约束、数据类型、用户定义的业务规则）在事务开始前和结束后都必须得到满足。一致性是原子性、隔离性和持久性共同作用的结果。数据库本身会强制执行一些约束（如唯一索引、外键检查），但应用层也需要确保业务逻辑的正确性。事务是保证一致性的重要手段，但不是唯一手段。如果事务破坏了约束，数据库会拒绝提交。
* 隔离型 Isolation：并发执行的事务之间应该相互隔离。一个事务的执行不应该影响其他并发执行的事务。目标是防止出现脏读 (Dirty Read)、不可重复读 (Non-repeatable Read) 和幻读 (Phantom Read) 等问题。
* 持久性 Durability：一旦事务成功提交（Commit），它对数据库所做的修改就是永久性的。即使发生系统崩溃、断电等故障，已提交的数据也不会丢失。InnoDB采用Write-Ahead-Logging（WAL）原则，日志（redo log）先于数据落盘。

关于脏读、不可重复读和幻读
* 脏读： 事务A读取了事务B修改但未提交的数据。如果事务B回滚，事务A读取到的就是无效的“脏”数据。
* 不可重复读： 事务A内多次读取同一数据。在事务A执行期间，事务B修改并提交了该数据。导致事务A两次读取的结果不一致（针对同一行数据的修改）。
* 幻读： 事务A根据一定条件读取了一些行。在事务A执行期间，事务B插入或删除了满足该条件的行并提交，导致事务A再次按相同条件读取时，发现多了（幻影行）或少了行（针对行集的插入/删除）。

为了解决上述问题，MySQL定义了4种隔离级别，隔离性由低到高，并发性由高到低：
* 读未提交 (READ UNCOMMITTED)： 最低级别。可能发生脏读、不可重复读、幻读。
* 读已提交 (READ COMMITTED)： 解决脏读。一个事务只能读取到其他事务已提交的数据，但可能发生不可重复读和幻读。Oracle默认是此隔离级别。
* 可重复读 (REPEATABLE READ)： 解决脏读和不可重复读。一个事务内多次读取同一数据的结果是一致的。MySQL InnoDB默认是此隔离级别。
* 串行化 (SERIALIZABLE)： 最高级别。事务串行执行，完全避免脏读、不可重复读、幻读。性能最低。

MySQL的性能（QPS 和 TPS）受很多因素的影响，包括硬件CPU性能、InnoDB内存缓冲区大小、硬盘速度、索引、SQL查询的复杂度、是否并发竞争行锁、事务包含的SQL语句多少等等。

如果只是简单的主键查询，并且数据在内存缓冲区中，MySQL的QPS可以达到几万，相对于Redis的10万QPS，其实也不算低。但是，如果查询是复杂查询，比如JOIN、聚合、嵌套等等，QPS可能下降到1万以下。如果数据没有在内存缓冲区中，需要在磁盘中查找，那么QPS可能下降到几千，从侧面上也可以得到，我们要将内存缓冲区大小（对应innodb_buffer_pool_size这个参数）设置的大一些，一般为机器内存的70% ~ 80%。如果全表扫描或不经过索引的查询，又或者高并发写场景下竞争行锁，QPS就有可能下降到几百。

还有一个表征MySQL性能的指标，那就是并发连接数，也就是可以支持的最大连接数。在MySQL5.6、MySQL8.0中，此配置参数（max_connections）默认为151。

在MySQL中，每个连接对应一个独立线程。除了线程栈之外，每个连接占用的内存还包括动态分配的缓冲区，比如排序缓冲区（sort_buffer_size）、JOIN缓冲区（join_buffer_size）等。这些缓冲区动态调整，随着查询的复杂度增加而增大，最大可以增至64MB。如果按照平均一个连接消耗10MB内存来算，1000个链接要消耗10GB的内存，这还不包括共享的InnoDB缓冲区（即innodb_buffer_pool_size）。

因此MySQL的最大连接数不应该设置过大，根据机器硬件性能，初始设置在300 ~ 500之间即可，后续根据监控（连接的使用情况、机器硬件资源的消耗情况、MySQL的整体性能，比如QPS）再做调整。如果最大连接数设置的过大，就会导致线程频繁切换、内存占用过多、并发竞争行锁加剧等问题，导致QPS下降、SQL执行时间增长，性能不增反降。

对于MySQL客户端来说，也就是Web后端服务，我们可以使用连接池来控制连接个数以及避免频繁连接。对于成千上万的接口请求，如果每个请求都重新与数据库建立连接，使用完之后再销毁连接，每次连接的建立都经历TCP三次握手、数据库认证、会话建立等耗时操作，这将是非常耗时的，影响Web服务器的接口响应时间，而且，对于数据库也是非常大的性能压力，频繁的建立销毁连接。数据库连接池就是为了解决这个问题而生的！

除了以上说到的性能优点之外，数据库连接池还有更多优点。
* 控制资源消耗：通过设置最大连接数，防止应用程序无限制地创建连接耗尽数据库连接。
* 统一管理：连接池负责连接的创建、验证、销毁、超时处理。
* 避免连接泄漏：严格的归还机制和泄漏检测有助于减少因代码错误导致的资源耗尽问题。
* 连接健康检查：确保应用程序拿到的连接是有效的，避免因网络闪断或数据库重启导致的连接失效错误。

MySQL 的高性能、高可用的扩展方案也无外乎这几种：主从复制保证高可用，读写分离保证高性能，分库分表是性能的终极大招。其实，基本上所有的存储类系统，他们实现高可用、高性能、海量存储、水平扩展的基本方案都是这几种，

## NoSQL 数据库
在某些应用场景下，我们并不需要强一致性事务，也不需要复杂关联查询，更不需要结构化出具存储，优点无用武之地，就成了限制，使其面临着：固定表结构带来的扩展困难，分布式场景的短板、高并发写入瓶颈等问题。
* 表结构扩展困难：产品经理临时加个用户标签字段，你得忙着改表结构；
* 高并发写入瓶颈：每秒要处理几十万条设备状态写入，写入可能成为瓶颈；
* 分布式扩展难题：单机撑不住想水平扩展时，分库分表带来的复杂度陡增。

这时候，NoSQL数据库登场了。它摒弃了关系型数据库引以为傲的 JOIN 操作，严格的 Schema，还有为了保证强一致性所做的种种努力，而是针对以上提到的特定应用场景，进行了针对性的存储设计和索引优化，使其发挥优于关系数据库的性能表现。

NoSQL 的设计哲学和关系型数据库很不一样，它从一开始就牺牲完美并拥抱分布式
* 灵活的数据模型：打破固定的 Schema 束缚，业务需要什么结构，我就存什么结构
* 分布式优先：从设计之初就考虑如何把数据和负载分散到成百上千台机器上。通过分区（Sharding）、复制（Replication）等技术，实现近乎线性的水平扩展能力。一台机器不够？加机器就行了。
* 简化查询：很多 NoSQL 数据库放弃了复杂的 SQL 和 JOIN 操作。查询模式通常更简单、更直接，比如根据主键（Key）快速获取值（Value），或者对文档中的某个字段进行索引查询。复杂的关联逻辑，更多地推给应用层来处理。这种“简化”换来了在特定查询模式下的极高性能。
* 调整一致性模型：不是所有场景都需要数据的强一致性（所有用户在任何时刻看到的数据都绝对一致）。NoSQL 常常采用“最终一致性”：系统保证在没有新的更新操作后，经过一段时间，所有副本的数据最终会达到一致。这种“弱化”换取的是更高的写入吞吐量和系统可用性。想想看，发一条微博，可能你刚发完自己立刻能看到，但你的粉丝列表里有人稍晚几秒才看到，这在很多场景下是完全可以接受的。

根据主要的数据模型和解决的问题，NoSQL 大致可以分为键值数据库、文档数据库、列式数据库、图数据库这样几类，每一类都有其擅长的战场。接下来我们就依次看下它们。
* 键值数据库：核心思想就是用 Key 快速找到 Value，可以把他想象成一个超级大的哈希表
* 文档数据库：键值数据库虽然性能很高，但只能通过 key 来查找 value，无法使用 value 中的字段进行查找，于是就有了文档数据库。文档数据库的基本实现原理是，将数据按照JSON等文档格式直接存储，文档中的字段可增可减，并且不要求每个文档的字段相同。对于需要用于查询的字段，均构建索引（可以是B+树、哈希表等），这样就可以实现基于任意想要的字段进行查询，解决了键值数据库只能通过一个键来查询的问题。除此之外，在系统设计中，当遇到用户画像、商品详情、内容管理这些字段变化频繁、结构不那么死板的数据时，关系型数据库常常显得笨重。每次加个字段都要改表结构，在大流量高并发下，这种“表结构变更”还可能成为性能瓶颈。文档数据库就能很好的解决这个问题。MongoDB 因其通用型强、社区活跃，成为最常用的文档数据库。
* 列式数据库：列式数据库（Columnar Database）是一类将数据按列而非行存储的数据库系统，特别适合海量数据分析、实时查询与高压缩场景。想象一张十亿用户的大表，传统数据库按行存储（把所有列数据放一起），查“用户年龄分布”得扫描整张表。而列数据库会把所有“年龄”值单独存储，查询时只读这一列，速度提升百倍。相比传统行式数据库，它在聚合计算、批量扫描和压缩效率上具有显著优势。特别适合海量数据存储、高并发写入的应用场景，比如用户行为日志存储、物联网传感数据、风控数据，以及作为数仓或者机器学习的底层数据存储。
* 图数据库：图数据库相对前面几种NoSQL数据库，用得少一些，因为它更加专精尖，主要存储图这种数据结构。虽然图数据库专精尖用得少，但是，一旦派上用场，就可以发挥立竿见影的作用。比如，存储超大社交网络之间的好友关系（比如，微博、微信），并且基于三度好友实现好友推荐功能，对于图数据库来说，存储和查找三度好友都很简单，并且查询性能也很高，相反，关系型数据库需要海量关系的存储，分库分表比较麻烦，并且，三度好友的查询需要经历多次数据库查询或者多层JOIN，性能跟图数据库有天壤之别！除此之外，图数据库还经常用在知识图谱、金融风控、推荐系统等有明显图特征的数据存储中。常用的图数据库有Neo4j、NebulaGraph、ArangoDB等等。

## 消息中间件
消息队列（Message Queue，简称MQ），也叫做消息中间件，它在构建高并发的分布式系统中，起到解耦、异步、削峰填谷的作用，可以说是系统架构设计的标配，也是后端面试中几乎必备的知识点。常用的消息中间件有RabbitMQ、Kafka、RocketMQ。在众多优秀的消息中间件中，RocketMQ 凭借其高吞吐、高可用、低延迟、高可靠的特性，以及丰富的功能和历经阿里巴巴双十一洪峰考验的实战经验，成为了国内乃至全球开发者非常青睐的选择。这节课我们就结合RocketMQ系统地讲一讲消息队列。

可以把 RocketMQ 的核心想象成一个大邮局系统，主要由 4 个核心角色组成
* Producer：好比寄信的人，负责产生消息并发送到邮局 Broker
* Broker：邮局本身，它接收 Producer 发来的信件，负责存储、管理和投递这些信件。一个 RocketMQ 集群通常由多个 Broker 组成，共同协作，保证服务不中断（高可用）和能处理海量信件（高吞吐）。
* Consumer：好比收信的人。它连接到邮局（Broker），告诉邮局“我想收某某地址的信”（订阅某个 Topic），然后 Broker 就会把相关的信件推送（或由 Consumer 主动拉取）给它。
* NameServer：可以理解为邮局的地址簿。Broker 启动时会把自己的地址（IP端口）和负责哪些“区域”（Topic）注册到 NameServer。Producer 和 Consumer 在发信或收信前，会先去 NameServer 查询“某某地址（Topic）该去哪个邮局（Broker）投递/收取”。

接下来，我们就来讲下消息的存储、索引和管理，也就是Broker的核心工作。在此之前，我们下来了解来年各个核心的 概念：Topic和Queue。

Topic(主题)：消息的逻辑分类，是生产者发送消息和消费者订阅消息的基本单位。你可以把它想象成一个大邮箱的标签或分类。生产者将不同类型的消息发送到不同的 Topic（例如：ORDER_TOPIC 用于订单消息，LOG_TOPIC 用于日志消息）。消费者则通过订阅感兴趣的 Topic 来接收其下的消息。它有点类似数据库中的表，不同的表存储不同的数据。

Queue(队列)：Topic 在物理层面的分片（Sharding）单位。这有点类似MySQL中的分表。这是 RocketMQ 实现并行处理、负载均衡和高吞吐的核心设计。一个 Topic 在创建时会被划分为一个或多个 Queue（数量可配置）。这些 Queue 会尽可能均匀地分布在集群的不同 Broker 上，当然也可以在一个Broker上（虽然不推荐）！

生产者发送消息到某个 Topic 时，RocketMQ 会根据一定的负载均衡策略（如轮询、哈希取模、随机等）选择一个该 Topic 下的 Queue，将消息最终存储在这个 Queue 对应的物理文件中。

消费者组 (Consumer Group) 订阅一个 Topic 时，该 Topic 下的 Queue 会被分配给组内的各个 Consumer 实例。例如，一个 Topic 有 8 个 Queue，一个 Consumer Group 有 4 个实例，那么理想情况下每个 Consumer 实例会负责消费 2 个 Queue 的消息。同一个 Queue 内的消息，在同一个 Consumer Group 内只会被一个 Consumer 实例串行消费。 不同 Queue 的消息可以被不同的 Consumer 实例并行消费。Queue 的数量直接决定了该 Topic 的最大消费并行度。

RocketMQ支持丰富的消息类型和灵活的消费模式。

丰富的消息类型
* 同步消息：Producer 发完消息后，会阻塞等待 Broker 返回确认。可靠性最高，但性能相对最低。适用于重要通知，如支付结果。
* 异步消息：Producer 发完消息立即返回，Broker 处理完后会异步回调 Producer 告知结果。性能和可靠性兼顾。
* 单向消息：Producer 只管发送，不等待确认也不关心结果。适用于日志收集等允许少量丢失的超高吞吐场景。
* 顺序消息：保证同一个 Queue 内的消息被 Consumer 按照发送顺序消费（比如同一个订单的创建、支付、发货消息要按顺序处理）。这是通过将需要保证顺序的消息发送到同一个 Queue 来实现的（局部有序）。
* 延迟消息： 消息发送后，不会立刻被 Consumer 消费，而是在指定的延迟时间（如 30 分钟、1 小时后）后才可消费。Broker 收到消息后不会立即投递，而是存储在特定的 SCHEDULE_TOPIC 下，由定时任务扫描到期后再投递到目标 Topic。常用于定时任务、关单提醒等。
* 事务消息： 解决分布式事务问题（如“本地数据库操作”和“发送消息”的一致性）。采用“半消息（Half Message） + 本地事务执行 + 二次确认”的机制，保证要么两者都成功，要么都失败（最终一致）。

灵活的消费模式
* 集群模式（Clustering）： 默认模式。同一个 Consumer Group 下的多个实例共同消费 Topic 的消息，实现负载均衡。一条消息只会被组内的一个实例消费。
* 广播模式（Broadcasting）： 同一个 Consumer Group 下的每个实例都会消费 Topic 的所有消息。

消息队列的主要用途有三个：解耦、异步、削峰，在日志处理、分布式事务、秒杀场景和订单超时取消等场景中都有中重要的应用。这些具体的应用我们后面会讲，这里只简单提及。
* 应用解耦：比如订单系统创建订单后，需要通知库存系统扣减库存、通知用户系统发优惠券、通知物流系统准备发货。如果订单系统直接同步调用这些系统，耦合度高，任一系统故障都会影响下单主流程。通过MQ，订单系统只需发一条“订单创建成功”的消息，其他系统各自订阅消费，实现解耦，提升核心链路稳定性和可维护性。
* 异步化处理：将非核心、耗时长的操作异步化。例如用户注册成功后，需要发送欢迎邮件、初始化用户画像、赠送积分等。注册服务只需发消息，后续操作由不同的 Consumer 异步完成，显著缩短用户注册响应时间。
* 流量削峰：应对突发流量，保护下游系统。比如秒杀活动，瞬间涌入大量下单请求。可以先快速将请求信息写入 MQ，再由下游的订单处理服务按照自身能力从 MQ 中拉取消息进行处理，避免瞬间压垮数据库或服务。

RocketMQ 显然是一个磁盘 IO 密集的应用。但是，得益于其顺序写磁盘、零拷贝、高效的网络模型，使其单机可轻松支持数万甚至十万级别的QPS，并且可以做到端到端毫秒级别的延迟和极高的消息堆积能力（完全取决于磁盘的大小）。

前面我们也提到，消息队列其实也可以看做是一种特殊的数据库。在讲解数据库的时候，我们讲到，为了提高性能和可用性，数据库一般支持多种扩展架构：主从复制、读写分离、数据分片。那么，消息队列也不例外。
* 主从复制：也就是Master-Slave结构，Producer将数据写入Master Broker之后，同步或者异步复制到Slave Broker，这样，即便Master Broker宕机，因为还有Slave Broker，所以，消息不会丢失，可以人工手动或者基于Raft等协议自动切换到Slave Broker继续服务，这样就提高了整体的可用性。
* 读写分离：Producer将消息写入Master Broker，Consumer负责从Slave Broker中读取消息，这样分担了Master的既要写又要读的压力。
* 数据分片：也叫做水平扩展。部署多个Broker，将不同的 Topic 分布到不同的 Broker 上，或者为同一个 Topic 创建更多的 Queue并分布在多个 Broker 上，从而提升整体吞吐能力。

消息队列在使用的过程中，有一些常见的经典问题，也是面试中经常问到的，比如消息队列、消息重复、消息幂等、延迟队列、有序消息、消息堆积等，这里我们一并简单讲下。

消息可能在生产、存储、消费三个阶段丢失
* 生产者端：网络闪断、进程崩溃导致消息未发出或 Broker 未收到。对策：使用同步发送（有确认）或可靠的异步发送（带回调检查），并实现发送重试机制（RocketMQ 客户端内置）。
* Broker 端：页缓存未刷盘机器掉电、磁盘损坏（单副本）、主从切换时异步复制未完成。对策： 配置 flushDiskType=SYNC_FLUSH（同步刷盘，性能下降但最可靠，异步刷盘性能更好但可靠性降低）；采用 Dledger 模式（基于 Raft 强同步复制，后面的文章会讲）保证主从数据一致和高可用；使用 RAID 或分布式存储保障磁盘可靠性（成本高）。
* 消费者端：消费成功并返回 CONSUME_SUCCESS 但业务逻辑没来得及执行，业务系统就崩溃，对策：并在业务逻辑处理完成且结果持久化之后再返回 CONSUME_SUCCESS。

重复几乎无法完全避免（网络重传、负载均衡重投、消费失败重试）。核心对策不是消灭重复，而是让消费逻辑能够安全地处理重复消息——即实现消息幂等。
* 生产者重复： 网络问题导致 Producer 重试，Broker 可能收到多条相同的消息。
* Broker 重投： Consumer 消费超时或返回失败，Broker 会重试投递。
* 负载均衡： Consumer 重启或队列重新分配，可能导致部分消息被重新消费（消费位置未及时提交）。

既然重复无法根除，消费端就必须实现幂等。幂等意味着：同一个操作（由相同的业务参数标识）被执行一次或多次，对系统状态的影响是相同的。 常见策略：
* 利用数据库唯一键：如订单 ID 作为唯一约束，重复插入会失败。这是最常用有效的方式。
* 业务状态机：检查消息对应的业务记录当前状态。如订单状态已是“已支付”，再收到支付消息则忽略。需要设计合理状态流转。
* 去重表：记录已处理成功的消息 ID（如 RocketMQ 的 msgId）或业务唯一标识。处理前先查表。注意 msgId 在 Broker 主从切换时可能重复（极低概率），更推荐使用业务唯一标识。

RocketMQ 强大的堆积能力是优点，但也可能掩盖问题，因为大量消息的堆积会严重影响消息处理的及时性。我们必须监控 Topic 的堆积量。一旦堆积持续增长，意味着消费速度跟不上生产速度，需要及时介入。是 Consumer 挂了？Consumer 性能瓶颈（代码效率低、DB 慢）？还是生产端流量异常激增？针对不同的情况，做不同的处理：
* 紧急扩容 Consumer 实例（增加消费能力）。
* 检查优化 Consumer 消费逻辑（如批量处理、异步化、减少 DB 操作）。
* 确认是否是正常业务高峰（如大促），做好容量规划。
* 极端情况（如消费逻辑完全不可用）：可能需要临时将堆积消息导出处理，或者（万不得已）在确保可追溯和可重放的前提下，跳过/丢弃部分非关键消息。

## 分布式协调
我们可以想象一下自己的开发团队，如果没有技术Leader、项目经理、产品经理等协调工作，每个人各自为战，就没法凝聚成一个高效的开发团队。分布式系统内部大规模集群协同工作，也需要这样的协作基础设施。比如以下几个功能，就是在很多分布式系统中都需要的。我们把这些共性的功能抽取出来做成一个独立的服务，就是分布式协调服务，比如前面提到的Zookeeper、Etcd、Nacos。
* 配置管理：分布式应用通常需要大量的配置信息（数据库连接、功能开关、超时设置等），将这些配置集中管理，而不是分散在每个应用实例的配置文件中，可以极大地简化管理、提高一致性和灵活性（无需重启应用即可动态更新配置）。利用分布式协调服务提供了一个中心化的、可靠的配置存储库，应用可以从这里拉取或监听配置变更。
* 服务发现：分布式应用通常需要大量的配置信息（数据库连接、功能开关、超时设置等），将这些配置集中管理，而不是分散在每个应用实例的配置文件中，可以极大地简化管理、提高一致性和灵活性（无需重启应用即可动态更新配置）。利用分布式协调服务提供了一个中心化的、可靠的配置存储库，应用可以从这里拉取或监听配置变更。
* 分布式锁：当多个服务节点需要互斥访问共享资源时（例如并发修改用户余额或抢占定时任务执行权），分布式锁确保仅一个节点可操作。节点向协调服务申请全局唯一锁标识，首获锁者执行关键操作（如库存扣减），通过心跳维持锁租约。操作结束显式释放锁后，其他等待节点立即被唤醒竞争。
* Leader选举：前面我们多次提到主从复制、故障自动转移，当主节点（即Leader）宕机之后，我们需要从其他从节点中选举出一个新的主节点，这个过程就是Leader选举。分布式协调服务就已经实现了现成的Leader选举功能。节点启动时注册参与选举，协调服务按规则（如最小节点ID）选定Leader并广播结果。Leader心跳超时触发新一轮选举，新Leader自动接管流量（如MySQL主库切换），保障服务连续性。

当年，只要Google出个新东西，市面上不就就会有对应的开源版本（这也说明在IT行业技术不是难点，创新才是）。GFS的开源版本是HDFS，BigTable的开源版本是HBase，MapReduce的开源版本是Hadoop MapReduce（跟HDFS、HBase三者组成Hadoop生态）。当然，Chubby也不例外，Chubby的开源版本是Zookeeper。

Zookeeper于2007年由雅虎内部开发的，其诞生的初衷也是因为内部的分布式系统，需要依赖这样一个通用的分布式协调服务，之后选择的开源。随后被迅速接受并应用（Hadoop生态、早期版本的Kafka都有用到它，还是开源影响力大！），也成为了分布式协调服务的标杆。当时针对分布式系统的开源组件并不多，因此，Zookeeper从功能上讲照顾了很多场景，可以说是大而全，基于它可以实现诸如数据发布 / 订阅、负载均衡、命名服务、分布式协调/通知、集群管理、Master 选举、分布式锁和分布式队列等诸多功能。

随着分布式技术的发展，很多基础系统开始拥抱分布式，迭代版本中加入了更多对分布式部署的支持，甚至很多系统从一开始就拥抱分布式。比如，Redis提供了Redis Sentinel、Redis Cluster。加上Raft协议的可实现性降低了开发门槛，从2020年以后，新一代分布式系统掀起了“去Zookeeper化”运动，使分布式协调服务，特别是Leader选举这一功能，从“独立中间件”下沉为“系统内生功能”。比如，Kafka把协调功能塞进了自己的KRaft模块，RocketMQ用DLedger内置选举，连Redis都自己实现了故障转移。为什么大家这么干？无非三个实在原因：内置Raft减少网络通信代价；无需独立部署分布式协调服务；除此之外，还可以定制功能和专项调优。

前面提到分布式协调的几个功能场景（配置中心、服务发现、分布式锁、Leader选举），部分功能的内置（比如Leader选举），部分功能的替代（Redis更多被应用于实现分布式锁），让分布式协调服务中间件逐渐收缩功能，于是像Nacos这样聚焦于配置管理和服务发现，并且简单易好用的分布式协调服务，在微服务中得到了更多应用。

Leader选举主要应用于主从架构中的故障自动转移，一般都是集成在基础系统内的功能，作为业务开发者大多不会去了解，分布式锁有替代实现方案，比如MySQL悲观锁、乐观锁、或者Redis Lua脚本，仅剩下的配置中心和服务发现又有Nacos来实现。每个功能场景都有独立的解决方案，集大成的分布式协调服务不再盛行，因此，很多开发者，特别是业务开发者，对分布式协调这个概念就淡化了，甚至都没听过，这也是我不大想讲这个知识点的原因。但是，了解这些可以让你对技术有个更高层次的了解，更容易将零散的技术关联起来，构建更合理的知识架构。这也是我最终决定讲一讲的原因。